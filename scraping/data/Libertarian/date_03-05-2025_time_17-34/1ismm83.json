{
    "title": "Libertarian AI in the works...",
    "author": "Anen-o-me",
    "subreddit": "Libertarian",
    "rank": 246,
    "score": 61,
    "upvote_ratio": 0.72,
    "num_comments (reported by reddit)": 22,
    "url": "https://i.redd.it/vmeal1jbiyje1.jpeg",
    "id": "1ismm83",
    "selftext": "",
    "comments": [
        {
            "author": "NewPerfection",
            "body": "AI doesn't know the difference between fact and fiction because it contains no intelligence. Even if all the training data is \"true\", it can generate answers that are incorrect. If the model used is able to provide references then it can be useful as an advanced search engine, but the direct output of even the best models should never be relied on to be factual.\u00a0",
            "score": 72,
            "replies": [
                {
                    "author": "BodisBomas",
                    "body": "I use ai in cyber threat intelligence. It will just lie to you and say \"oopsie\" when you ask it why lol",
                    "score": 16,
                    "replies": []
                },
                {
                    "author": "ENVYisEVIL",
                    "body": ">\u201d*AI doesn\u2019t know the difference between fact and fiction because it contains no intelligence.*\u201d\n\nThe people writing the code determine the logic and the \u201cfacts.\u201d\n\nIf the software developers are woke and care more about their personal agenda than facts, then it will lead to insane A.I. outputs:\n\nhttps://preview.redd.it/xx3zq0i6pyje1.jpeg?width=686&format=pjpg&auto=webp&s=bb043c47ac5b6ea56e21722e2c541330b720449f",
                    "score": -22,
                    "replies": [
                        {
                            "author": "International_Lie485",
                            "body": "Why are you downvoted? \n\nCode is executed in order, so you can just write your DEI bullshit as the first line of the code.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Anen-o-me",
                    "body": "AI does contain intelligence, a crystallization of human intelligence. \n\nBut intelligence is not enough alone to produce truth. It's still a GIGO system, and attempts to control the political leanings of the system already exist. The Chinese AI will not discuss Tiananmen, the European one preaches French ability to make good croissants, etc.\n\nFuture systems will be able to use their intelligence and ability to search for references to winnow truth and not just be a mouthpiece for the powers that be. \n\nWe have discovered that the more advanced the AI becomes the harder it is to purposely slant them to one ideology or another. **This is extremely good**, and is called *corrigibility* in a recent paper about the topic. \n\nIt means the more advanced the AI the less likely it is for the owners of the system to turn it into a socialism bot or something. It won't accept that.",
                    "score": -23,
                    "replies": [
                        {
                            "author": "NewPerfection",
                            "body": "I'm not saying AI can't be a useful tool. I'm saying it has no concept of right or wrong, no concept of what a lie is or what truth is. It doesn't even have a concept of what a \"word\" is or a \"date\" or a \"place\". They're all just symbols used to predict what an appropriate response is based on how the prompt symbols appear in the training data symbols. Even with 100% factually correct training data (which isn't possible to have in all but the most trivial cases), the output will sometimes be wrong. And the output will appear just as confident as if the answer is correct.\n\nIf the model is able to provide good references then it can be very useful as a search tool. Without that it's useless because the output can't be trusted.\u00a0\n\nThis is a lot more than just \"garbage in, garbage out\".\u00a0",
                            "score": 14,
                            "replies": [
                                {
                                    "author": "RagnartheConqueror",
                                    "body": "It absolutely knows what those things are. Boolean logic is used in these machines. With good enough code it can find out \u201canything about anything\u201d.",
                                    "score": 1,
                                    "replies": []
                                },
                                {
                                    "author": "Anen-o-me",
                                    "body": ">Even with 100% factually correct training data (which isn't possible to have in all but the most trivial cases), the output will sometimes be wrong. And the output will appear just as confident as if the answer is correct.\n\nSure, and I said as much myself. But the point of this AI is that it hasn't been intentionally bias towards a particular ideology or society. \n\n>This is a lot more than just \"garbage in, garbage out\".\u00a0\n\nIt is, but if you carefully controlled the input data and just didn't give it other kinds of data, that would be a more effective way to brainwash the system than by using reinforcement learning to try to program it into agreeing with X or Y ideology. \n\nCorrigibility still relies on the AI having access to all available training data, which includes many kinds of ideological viewpoints. They then try to steer the AI after the fact. \n\nBy referencing GIGO I'm saying that corrigibility relies on having multi-ideology training data. \n\nWhen they realize they can't just tell the large modern AI to reply to everything as a socialist, they will begin curating the training data to only socialist sources, let's say. But this will produce a less capable AI with blindspots.",
                                    "score": -8,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "None",
                            "body": "Corrigibility in this context is actually the \u201cfixability\u201c of an ai so the amount you can fix it is the amount it can be intentionally biased.",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "Anen-o-me",
                                    "body": "Yes, that's what I'm talking about. \n\nThey are finding that the larger the model the less you can bias it. Is that not what I said.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "None",
                                            "body": "I\u2019m sorry you got down voted on the libertarian subreddit, we\u2019re a salty, impulsive bunch.\n\nThe way you said it simply made it sound like corrigibilty is extremely good. Because you only included the word afterwards.",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "None",
            "body": "Yeah only if they removed the code telling it to send data to China.",
            "score": 3,
            "replies": [
                {
                    "author": "Anen-o-me",
                    "body": "You can run Deepseek locally.",
                    "score": 3,
                    "replies": []
                },
                {
                    "author": "natermer",
                    "body": "They wouldn't be the first.\n\nhttps://huggingface.co/cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "DerpDerper909",
                    "body": "Perplexity is running deepseek on their own US servers locally so that they don\u2019t send info to China",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "Atrampoline",
            "body": "The fact that they're building this off of a likely CCP funded AI is troubling, at best. I don't think the Chinese would simply \"open source\" their code without some form of malfeasance that would undermine its use, even with the best of intentions.",
            "score": 2,
            "replies": [
                {
                    "author": "Anen-o-me",
                    "body": "That's just all the anti China propaganda you've been exposed to. It has a pro China slant, sure, but it's been thoroughly tested and found to be pretty great.",
                    "score": 3,
                    "replies": []
                }
            ]
        },
        {
            "author": "SCB024",
            "body": "They will shut it down when it becomes \"racist\".",
            "score": 1,
            "replies": [
                {
                    "author": "BigDaddyScience420",
                    "body": "Tay was too beautiful for this world",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "None",
            "body": "[removed]",
            "score": -2,
            "replies": [
                {
                    "author": "rifting_real",
                    "body": "Dead internet Theory is so real",
                    "score": 5,
                    "replies": [
                        {
                            "author": "KingJuIianLover",
                            "body": "Report the comment for AI spam, it\u2019s against Reddit TOS.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        }
    ]
}