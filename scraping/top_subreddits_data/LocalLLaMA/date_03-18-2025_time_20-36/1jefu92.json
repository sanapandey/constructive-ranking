{
    "title": "NVIDIA Enters The AI PC Realm With DGX Spark & DGX Station Desktops: 72 Core Grace CPU, Blackwell GPUs, Up To 784 GB Memory",
    "author": "_SYSTEM_ADMIN_MOD_",
    "subreddit": "LocalLLaMA",
    "rank": 18,
    "score": 20,
    "upvote_ratio": 0.89,
    "num_comments (reported by reddit)": 12,
    "url": "https://wccftech.com/nvidia-enters-ai-pc-realm-dgx-spark-dgx-station-desktops-72-core-grace-cpu-blackwell-gpus-up-to-784-gb-memory/",
    "id": "1jefu92",
    "selftext": "",
    "comments": [
        {
            "author": "realcul",
            "body": "did they announce the approx. price of this ?",
            "score": 1,
            "replies": [
                {
                    "author": "Captain_Blueberry",
                    "body": "The price of Jensen's jacket",
                    "score": 5,
                    "replies": []
                },
                {
                    "author": "redoubt515",
                    "body": "Considering that Digits gets you a rather lackluster 128GB RAM @ 270 GB/s for $3000, I'm guessing what is being announced here will be like an order of magnitude more expensive,. Somewhere between exorbitant and comically expensive for individuals.",
                    "score": 5,
                    "replies": []
                },
                {
                    "author": "Vb_33",
                    "body": "It has a Blackwell Ultra B300 in it so expect north of $20k.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "HugoCortell",
            "body": "From the way it is described, it seems like the DGX uses unified memory like the new Macs do. A clever way to keep costs down while still offering very good performance for inference. Of course, knowing Nvidia, they'll pocket these costs savings rather than passing them down to the consumer.\n\nIt's got nearly 300GB of actual VRAM, which is tremendous. It also uses some weird proprietary network connector for some reason, which is less tremendous. \n\nIf they allowed it, I'd absolutely buy this without a GPU at all and enjoy a cheap ML inference machine with 500gb of RAM. But something tells me that no matter what variations are offered, this stuff is going to start at the cost of a used luxury car and only go up from there.\n\nIts easy to get excited reading the headlines, and then easy to completely stop caring when you realize you can't afford to spend you entire savings on a cool piece of hardware.",
            "score": 1,
            "replies": [
                {
                    "author": "Vb_33",
                    "body": "DGX Spark uses LPDDR5X like the Macs do but DGX Station has GPU memory (HBM3) and system memory (LPDDR5X) linked up and coherent.\u00a0",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "BABA_yaaGa",
            "body": "Lol, apple had only one thing going and now that too is taken away",
            "score": -15,
            "replies": [
                {
                    "author": "PermanentLiminality",
                    "body": "Apple will probably be the budget option.",
                    "score": 8,
                    "replies": [
                        {
                            "author": "dinerburgeryum",
                            "body": "Yeah no way you\u2019re allowed to even look at one in the consumer market",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "ElementNumber6",
                                    "body": "\"Please contact us for pricing\"",
                                    "score": 5,
                                    "replies": [
                                        {
                                            "author": "Mart-McUH",
                                            "body": "That makes no sense because... \"If you have to ask...\"",
                                            "score": 2,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    ]
}