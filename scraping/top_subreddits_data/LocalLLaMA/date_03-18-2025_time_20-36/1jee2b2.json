{
    "title": "NVIDIA DGX Spark (Project DIGITS) Specs Are Out",
    "author": "spectrography",
    "subreddit": "LocalLLaMA",
    "rank": 9,
    "score": 60,
    "upvote_ratio": 0.91,
    "num_comments (reported by reddit)": 30,
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1jee2b2/nvidia_dgx_spark_project_digits_specs_are_out/",
    "id": "1jee2b2",
    "selftext": "[https://www.nvidia.com/en-us/products/workstations/dgx-spark/](https://www.nvidia.com/en-us/products/workstations/dgx-spark/)\n\nMemory bandwidth: 273 GB/s",
    "comments": [
        {
            "author": "spectrography",
            "body": "Now we know why they have been so quiet about memory bandwidth LOL",
            "score": 60,
            "replies": [
                {
                    "author": "Rich_Repeat_22",
                    "body": "Well we knew actually 2 months now. Cannot go higher with LPDDR5X. Maybe if using 9600Mhz modules on quad channel but still the speed is around 256-273 for quad channel.",
                    "score": 11,
                    "replies": [
                        {
                            "author": "Massive-Question-550",
                            "body": "i think the obvious hope was that it would be 8 channel memory like mac products. its not like nvidia cant do it while apple can, they just dont want to.",
                            "score": 19,
                            "replies": [
                                {
                                    "author": "segmond",
                                    "body": "They had such a grip on the market, if they made the decision today based on how the stock market is doing, I bet they would have been nicer.  But they thought it was literally to the moon and never down.",
                                    "score": 13,
                                    "replies": []
                                },
                                {
                                    "author": "Vb_33",
                                    "body": "Nvidia has 2 DGX desktop workstations, DGX Sparks the lower end one and DGX Station the higher end one.\n\n\n\n\nDGX Sparks (formerly Project DIGITS). A power-efficient, compact AI development desktop allowing developers to prototype, fine-tune, and inference the latest generation of reasoning AI models with up to 200 billion parameters locally.\u00a0\n\n\n* 20 core Arm, 10 Cortex-X925 + 10 Cortex-A725 Arm\u00a0\n\n\n* GB10 Blackwell GPU\n\n\n* 256bit 128 GB LPDDR5x, unified system memory, 273 GB/s of memory bandwidth\u00a0\n\n\n* 1000 \"AI tops\", 170W power consumption\n\n\n\n\nDGX Station: The ultimate development, large-scale AI training and inferencing desktop.\n\n\n* 1x Grace-72 Core Neoverse V2\n\n\n* 1x NVIDIA Blackwell Ultra\n\n\n* Up to 288GB HBM3e | 8 TB/s GPU memory\u00a0\n\n\n* Up to 496GB LPDDR5X | Up to 396 GB/s\u00a0\n\n\n* Up to a massive 784GB of large coherent memory\u00a0\n\n\n\n\nAs you can see DGX Station has a Blackwell Ultra B300 with 288GB of HBM3 at 8TBs of bandwidth.\u00a0",
                                    "score": 2,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "-6h0st-",
                    "body": "Btw price I was given was 4k for one 8k for two.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "hurrdurrmeh",
            "body": "Isn\u2019t apple like 800GB/s?",
            "score": 20,
            "replies": [
                {
                    "author": "LevianMcBirdo",
                    "body": "Tbf that's on a machine that starts at 5k with 96 GB RAM. Still digits is pretty much dead on arrival. Framework offers the same on x86 for 1k less and Mac offers way faster speeds for 2k more.",
                    "score": 21,
                    "replies": [
                        {
                            "author": "-6h0st-",
                            "body": "Spark is for 4k - so pretty much M3U binned with 96GB or more expensive than M4M with 128GB but running at double 576GB/s whilst useful computer",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "5dtriangles201376",
                                    "body": "I\u2019m confused, can I get a link?",
                                    "score": 2,
                                    "replies": []
                                },
                                {
                                    "author": "Vb_33",
                                    "body": "$4000 is for the Spark Founders edition with 4TB of storage. Spark starts at $2999 for the Asus 1TB version.\u00a0",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Rich_Repeat_22",
                    "body": "And? Tbh the more I dig through the Apple machines the more I see that the chip is not adequate for the job.",
                    "score": -31,
                    "replies": [
                        {
                            "author": "Lordxb",
                            "body": "Runs Deepseek at full at 18tks so it\u2019s good enough compared to this hot mess of a device with same form factor!!",
                            "score": 14,
                            "replies": [
                                {
                                    "author": "Mountain_Station3682",
                                    "body": "\\*at 4bit (\\~400 GB)",
                                    "score": 1,
                                    "replies": []
                                },
                                {
                                    "author": "Rich_Repeat_22",
                                    "body": "Who runs 600B FP8 Deepseek at 18tks? \ud83e\udd14",
                                    "score": -18,
                                    "replies": [
                                        {
                                            "author": "h1pp0star",
                                            "body": "Definitely not the new NVIDIA DGX Spark",
                                            "score": 15,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Kirys79",
            "body": "So like a 128gb 4060TI (from a memory bandwidth POV...)",
            "score": 11,
            "replies": []
        },
        {
            "author": "anzzax",
            "body": "What a bummer :(",
            "score": 6,
            "replies": []
        },
        {
            "author": "this-just_in",
            "body": "This feels pretty sad. \u00a0The only upside with this product is CUDA support.",
            "score": 6,
            "replies": [
                {
                    "author": "animealt46",
                    "body": "In fairness that's a pretty big upside if you are developing models.",
                    "score": 6,
                    "replies": []
                }
            ]
        },
        {
            "author": "EasternBeyond",
            "body": "DOA. With reasoning models, the speed is too slow.",
            "score": 7,
            "replies": []
        },
        {
            "author": "agentzappo",
            "body": "Its an upgrade over the AGX Orin: 1.33x memory bandwidth (273 GB/s vs. 204.8 GB/s), native FP8, and 2x the unified memory. Everyone wants everything, but for an all-in-one solution running Linux this is going to sell",
            "score": 2,
            "replies": [
                {
                    "author": "animealt46",
                    "body": "Strange rebrand to DGX tho.",
                    "score": 2,
                    "replies": [
                        {
                            "author": "Joshsp87",
                            "body": "AMD's APU is a much easier sell IMO. I still reserved the \"DGX\" though",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Magnus919",
            "body": "Ok so not getting that one\u2026",
            "score": 1,
            "replies": []
        },
        {
            "author": "PassengerPigeon343",
            "body": "Woof",
            "score": 1,
            "replies": []
        },
        {
            "author": "thisusername_is_mine",
            "body": "Overpriced garbage.",
            "score": 1,
            "replies": []
        },
        {
            "author": "Balance-",
            "body": "Exact same memory bandwidth as the Apple\u00a0M4 Pro.",
            "score": -1,
            "replies": []
        }
    ]
}