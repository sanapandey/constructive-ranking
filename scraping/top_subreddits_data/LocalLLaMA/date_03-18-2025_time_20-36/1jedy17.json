{
    "title": "Nvidia digits specs released and renamed to DGX Spark",
    "author": "Terminator857",
    "subreddit": "LocalLLaMA",
    "rank": 3,
    "score": 162,
    "upvote_ratio": 0.94,
    "num_comments (reported by reddit)": 170,
    "url": "https://www.reddit.com/r/LocalLLaMA/comments/1jedy17/nvidia_digits_specs_released_and_renamed_to_dgx/",
    "id": "1jedy17",
    "selftext": "https://www.nvidia.com/en-us/products/workstations/dgx-spark/\nMemory Bandwidth \t273 GB/s\n\nMuch cheaper for running 70gb - 200 gb models than a 5090.  Cost $3K according to nVidia.  Previously nVidia claimed availability in May 2025.  Will be interesting tps versus https://frame.work/desktop",
    "comments": [
        {
            "author": "coder543",
            "body": "Framework Desktop is 256GB/s for $2000\u2026 much cheaper for running\u00a070gb - 200 gb models than a Spark.",
            "score": 160,
            "replies": [
                {
                    "author": "xor_2",
                    "body": "Yup, and being X86 is much more usable. These small AMD APUs are quite nice for a console/multi-media box purposes when not using LLMs. Nvidia offering is ARM so Linux only and not even X86 Linux so pretty much no gaming will be possible.",
                    "score": 62,
                    "replies": [
                        {
                            "author": "FullOf_Bad_Ideas",
                            "body": "it's AMD tho so no CUDA. x86+CUDA+quick unified memory is what I want.",
                            "score": 25,
                            "replies": [
                                {
                                    "author": "nother_level",
                                    "body": "Vulkan is getting better and better for inference it's basically just as good now.",
                                    "score": 16,
                                    "replies": [
                                        {
                                            "author": "FullOf_Bad_Ideas",
                                            "body": "I do batch inference with vLLM, SGLang, and also image and video gen with ComfyUI + Hunyuan/WAN/SDXL/FLUX. All of that basically needs x86+CUDA config just to start up without a hassle",
                                            "score": 5,
                                            "replies": [
                                                {
                                                    "author": "dobkeratops",
                                                    "body": "I'd bet that the AMD devices coming will encourage more people to work on vulkan support. Inference of the popular models isn't as hard as getting all the researchers on board",
                                                    "score": 4,
                                                    "replies": [
                                                        {
                                                            "author": "FullOf_Bad_Ideas",
                                                            "body": "honestly, dunno. AMD will always find a way to fail in a market.\n\nBut realistically, AMD doesn't have any strong GPU with compute that would even match 4090 for AI workloads. Hardly anyone will want to spend time on fixing stuff for miniPC APU chip like Ryzen AI 395+ which I think has a tiny compute power compared to 3090 or DIGITS.",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "nother_level",
                                                    "body": "Literally all of them have vulkan support out of box what are you on about",
                                                    "score": 13,
                                                    "replies": [
                                                        {
                                                            "author": "tommitytom_",
                                                            "body": "ComfyUI does not have Vulkan support",
                                                            "score": 8,
                                                            "replies": [
                                                                {
                                                                    "author": "nother_level",
                                                                    "body": "Yeah mb I used it for almost year on my amd card so I thought it did support, it supports rocm tho",
                                                                    "score": 5,
                                                                    "replies": []
                                                                },
                                                                {
                                                                    "author": "noiserr",
                                                                    "body": "For inference ROCm is just as good these days. With most popular tools.\n\nAs long as you're on Linux. But digits is linux only anyway.\n\nComfyUI supports ROCm: https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#amd-gpus-linux-only",
                                                                    "score": 1,
                                                                    "replies": []
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "author": "FullOf_Bad_Ideas",
                                                            "body": "Can you point me to a place that mentions that vLLM has Vulkan support?\n\nCan I make videos with Wan 2.1 on it in ComfyUI?",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "author": "gofiend",
                                            "body": "Is this true? Is Vulkan on a 3090/4090 as fast as CUDA? (say using VLLM or llama.cpp?)",
                                            "score": 1,
                                            "replies": [
                                                {
                                                    "author": "nother_level",
                                                    "body": "https://www.phoronix.com/news/NVIDIA-Vulkan-AI-ML-Success",
                                                    "score": 6,
                                                    "replies": [
                                                        {
                                                            "author": "gofiend",
                                                            "body": "Super interesting. Looks like Vulkan with VK\\_NV\\_cooperative\\_matrix2 is almost at parity (but a little short) with CUDA on a 4070 except (wierdly enough) on 2bit DeepSeek models.\n\nClearly we're at the point where they are basically neck and neck barring ongoing driver optimizations!",
                                                            "score": 4,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "imtourist",
                                    "body": " How many people are actually going to be training such that hey need CUDA?",
                                    "score": 10,
                                    "replies": [
                                        {
                                            "author": "FullOf_Bad_Ideas",
                                            "body": "AI engineers, which I guess are the target market, would train. DIGITS is sold as a workstation to do inference and finetuning on. It's a complete solution. You can also run image / video gen models, and random projects off github, hopefully. With AMD, you can run LLMs fairly well. And some image gen models, but with greater pain at lower speeds.",
                                            "score": 5,
                                            "replies": [
                                                {
                                                    "author": "nmstoker",
                                                    "body": "Yes, I think you're right. Regarding GitHub projects it'll depend on what's supported but provided the common dependencies are sorted this should be mostly fine. Eg pytorch already supports ARM+CUDA, https://discuss.pytorch.org/t/pytorch-arm-cuda-support/208857\n\nAnd given it's Linux based, a fair amount will just compile, which is generally not so easy on Windows.",
                                                    "score": 2,
                                                    "replies": []
                                                },
                                                {
                                                    "author": "noiserr",
                                                    "body": "> AI engineers, which I guess are the target market, would train.\n\nThis is such underpowered hardware for training though. I'd imagine you'd rent cloud GPUs.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "author": "FullOf_Bad_Ideas",
                                                            "body": "yes but you may want to prototype and do some finetuning locally, we're on localllama after all.\n\nI prefer to finetune models locally wherever it's reasonable, otherwise you don't see GPUs brrr.\n\nIf i would be buying a new hardware, it would be some npu that I could train (moreso finetune than train right) and inference on, inference only hw is pretty useless IMO.",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Charder_",
                                    "body": "I can see why people are seeking alternatives to Nvidia while others have no choice but to seek out Nvidia.",
                                    "score": 5,
                                    "replies": []
                                },
                                {
                                    "author": "un_passant",
                                    "body": "Is CUDA required for inference ? And isn't the Spark too slow for training anyway ?",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "author": "FullOf_Bad_Ideas",
                                            "body": "I don't do inference only, and when I do it's SGLang/vLLM. Plus it's often basically required for various projects I run from GitHub - random AI text to 3d object, text to video, image to video. This plus finetuning 2B-34B LLM/VLM/T2V/ImageGen models locally. I don't think I would be able to do that smoothly without GPU that supports CUDA.\n\nRegarding Spark (terrible name, DIGITS was 10x better..) use for finetuning - we'll see. I think they kinda marketed it as such.",
                                            "score": 2,
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "xor_2",
                                    "body": "CUDA vs Windows/games... depends on use case I guess.\n\nThese Nvidia DGX computers seem like they could be sitting there and mulling over training data all day and all night long training relatively decent sized models at fp8 (should have cuda10 capability just like blackwell)\n\nTraining on AMD... actually maybe it is possible with Zluda framework? Maybe it is somethign that will get more attention in the coming months.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "FullOf_Bad_Ideas",
                                            "body": "AMD 395+ AI has relatively high memory bandwidth and size going for it given accessible price, but it doesn't have compute for anything too serious, even with ZLUDA or other tricks.\n\nDigits should be better there - like at least it should be usable for some things, 3090/4060 level of performance\n\nDGX Station is a serious workstation that I could see myself working on without needing to reach for cloud GPUs often.",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "CatalyticDragon",
                                    "body": "Sure but does CUDA do anything you need? AMD has HIP which is a CUDA clone and runs all the same models. You can port code rather easily.\n\nThere's also of course get support for Vulkan, DirectML, Triton, OpenCL, SYCL, OpenMP, and anything else open and/or cross platform.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "FullOf_Bad_Ideas",
                                            "body": "Yes, I work on my computer and use finetuning/inference frameworks on cloud GPUs when my local GPU/GPUs aren't enough. I use stuff that's compatible with CUDA, which is the majority. 90% of training frameworks don't support AMD at all, and though AMD is somewhat supported in production grade inference frameworks, it's still much tricker to setup and support ends at datacenter GPUs - your 192GB HBM $10k MI300X accelerator might be supported, so you can slap a badge of \"Supports AMD\" on it, but consumer cards like 7900 XTX might have an issue running it.",
                                            "score": 1,
                                            "replies": [
                                                {
                                                    "author": "Mental_Judgment_7216",
                                                    "body": "Thank you man.. I\u2019m tired of saying it. \u201cSupports AMD\u201d is a meme at this point. I got a 9070xt and I\u2019m just spoiled coming from Nvidia, everything needs some sort of comparability workaround and it\u2019s just exhausting. I\u2019m returning the card first thing in the morning and just waiting for 5080s to come back in stock. I mostly game but I\u2019m also an ai hobbyist.",
                                                    "score": 2,
                                                    "replies": []
                                                },
                                                {
                                                    "author": "CatalyticDragon",
                                                    "body": ">90% of training frameworks don't support AMD at all\n\nI might debate that. I can't think of any which don't support ROCm but then again I only think of Torch & TF/Keras. What are you thinking of?\n\nAnd what would you plan on using an NVIDIA Spark for that you think an AMD chip with ROCm couldn't also do? \n\nOr is it more of a perception thing?",
                                                    "score": 1,
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "divided_capture_bro",
                            "body": "Are you saying I won't be able to play floppy birds on my supercomputer?",
                            "score": 1,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "boissez",
                    "body": "Yeah and Framework has a x4 Pcie 4.0 slot you can add a GPU to.",
                    "score": 10,
                    "replies": [
                        {
                            "author": "None",
                            "body": "[deleted]",
                            "score": -3,
                            "replies": [
                                {
                                    "author": "Ok_Top9254",
                                    "body": "You can run a gpu off an x1 slot...",
                                    "score": 5,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "greentea05",
                    "body": "Or for \u00a3500 more you can get 410GB/s with a Mac Studio which you can also use as Mac!",
                    "score": 6,
                    "replies": [
                        {
                            "author": "cobbleplox",
                            "body": "> which you can also use as Mac\n\nI knew there was a catch",
                            "score": 41,
                            "replies": [
                                {
                                    "author": "Conscious-Tap-4670",
                                    "body": "That'd be a perk over windows ;)",
                                    "score": -4,
                                    "replies": [
                                        {
                                            "author": "potpro",
                                            "body": "10-15 years late on that.. ;op",
                                            "score": 3,
                                            "replies": [
                                                {
                                                    "author": "Conscious-Tap-4670",
                                                    "body": "WSL2: When you have to make your OS more like linux to make it bearable for development",
                                                    "score": -1,
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "ArtyfacialIntelagent",
                            "body": "Of course you'll need some additional SSD storage with that so you can hoard a few LLMs. An upgrade from 1TB to 2TB costs \u00a3400, and you pay \u00a31000 to go from 1TB to 4TB. Now you might think that \u00a3333-400 per TB is a steep price to pay for storage - it really is, but keep in mind that it could be worse. The market price of a top spec 4 TB Samsung 990 Pro M.2 SSD is about \u00a3260, i.e. \u00a365/TB, so Apple showed admirable restraint and respect for its customers when it settled for just a 5-6x markup over its competitors.",
                            "score": 5,
                            "replies": [
                                {
                                    "author": "tyb-markblaze82",
                                    "body": "could i just rip the 4tb nvme storage i have already in my PC and put it into the mac then sell my 1 year old built PC with a 3090 and a 3060 12GB to cushion the price of the mac? not sure how mac's work if i can add my own storage or not but seen as my PC is only for learning/using AI/ML it seems like a better route than digits. im kinda gutted i hoped we where getting something good when i heard about digits and was following the news but i knew we would get gimped somehow with the usual this could be better but this is what your getting NVIDIA mentality.",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "coder543",
                            "body": "You mean \u00a33500, not \u00a32500, right?",
                            "score": 4,
                            "replies": []
                        },
                        {
                            "author": "eleqtriq",
                            "body": "As we just saw with the Ultra, the memory bandwidth is not the whole story.",
                            "score": 3,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "noiserr",
                    "body": "You can also just get barebones only if you're stacking multiple in which case it's $1700 per motherboard/APU combo.",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "dobkeratops",
                    "body": "there's a $3000 ASUS version of the DGX Spark (128gb ram/1tb drive) and these devices come with 'ConnectX-7' networking, \"400gbit/sec\" .. if you actually get 50gbyte/sec data sharing when you pair 2 boxes up that might still be a game changer.\n\nI agree though overall this its ambiguous which is better.",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "None",
                    "body": "[deleted]",
                    "score": 0,
                    "replies": []
                }
            ]
        },
        {
            "author": "According-Court2001",
            "body": "Memory bandwidth is so disappointing",
            "score": 100,
            "replies": [
                {
                    "author": "Rich_Repeat_22",
                    "body": "But we expected it be in that range for 2 months.",
                    "score": 34,
                    "replies": [
                        {
                            "author": "ElementNumber6",
                            "body": "To be fair, there's been a whole lot of expressed disappointment since the start of that 2 months",
                            "score": 22,
                            "replies": []
                        },
                        {
                            "author": "TheTerrasque",
                            "body": "Some of us, yes. Most were high on hopium and I've even gotten downvotes for daring to suggest it might be lower than 500+gb/s",
                            "score": 14,
                            "replies": [
                                {
                                    "author": "Rich_Repeat_22",
                                    "body": "Remembering the downvotes got for saying around 256GB/s \ud83d\ude02\n\nWith NVIDIA announcing the RTX A 96GB pro card at something around $11000, selling 500GB/s 128GB machine for $3000 would be cannibalizing of the pro card sales.",
                                    "score": 9,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "mckirkus",
                    "body": "Anybody want to guess how they landed at 273 GBytes/s?  Quad channel DDR-5?  32x4 GByte sticks?",
                    "score": 8,
                    "replies": [
                        {
                            "author": "coder543",
                            "body": "https://www.reddit.com/r/LocalLLaMA/comments/1hwthrq/why_i_think_that_nvidia_project_digits_will_have/",
                            "score": 5,
                            "replies": [
                                {
                                    "author": "tyb-markblaze82",
                                    "body": "massive respect to that guy how he figured it out",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "Linkpharm2",
                            "body": "Ddr5x 256bit",
                            "score": 2,
                            "replies": [
                                {
                                    "author": "wen_mars",
                                    "body": "LPDDR5x. DDR5x doesn't exist.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "Linkpharm2",
                                            "body": "Whoops",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "PassengerPigeon343",
                    "body": "This makes me glad I went the route of building a PC instead of waiting. Would have been really nice to see a high-memory-bandwidth mini pc though.",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "Final-Rush759",
                    "body": "For $3000, it needs to be around 500 GB/sec.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "fairydreaming",
            "body": "[...](https://www.reddit.com/r/LocalLLaMA/comments/1hwthrq/why_i_think_that_nvidia_project_digits_will_have/)",
            "score": 75,
            "replies": [
                {
                    "author": "fightingCookie0301",
                    "body": "Hehe, it\u2019s 69 days ago since you posted it.\n\nJokes aside, you did a good job analysing it :)",
                    "score": 11,
                    "replies": []
                },
                {
                    "author": "fmlitscometothis",
                    "body": "You're ridiculous \ud83d\ude02\ud83d\udc4f\ud83d\udc4f",
                    "score": 7,
                    "replies": []
                },
                {
                    "author": "Comfortable_Relief62",
                    "body": "Absolute genius",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "gwillen",
                    "body": "Be careful, some fucking hedge fund is gonna try to hire you to do that full-time. XD",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "extopico",
            "body": "This seems obsolete already. I\u2019m not trying to be edgy, but the use case for this device is small models (if you want full context, and reasonable inference speed). It can run agents I guess. Cannot run serious models, cannot be used for training, maybe OK for fine tuning of small models. If you want to network them together and build a serious system, it will cost more, be slower and more limited in its application than a Mac, or any of the soon to be everywhere AMD x86 devices at half the price.",
            "score": 18,
            "replies": []
        },
        {
            "author": "ForsookComparison",
            "body": "If I wanted to use 100GB of memory for an LLM doesn't that mean that I'll likely be doing inference at 2 tokens/s before context gets added?",
            "score": 15,
            "replies": [
                {
                    "author": "windozeFanboi",
                    "body": "Yes, but the way I see it, is not maxing out with a single model, but maxing it out with a slightly smaller model + draft model + other tools needing memory as well.\n\n\n128GB 256GB/s I'd simply so comfortable for 70B +draft model for extra speed, +32k context + ram for other tools and the OS.\u00a0",
                    "score": 14,
                    "replies": []
                }
            ]
        },
        {
            "author": "Rich_Repeat_22",
            "body": "Well, the overpriced Framework Desktop 395 128GB is $1000 cheaper for similar bandwidth. The expected miniPCs from several vendors even cheaper than the Framework Desktop.\n\nAnd we can run out of the box Windows/Linux on these machines, play games etc. Contrary to Spark which is limited to the specialised NVIDIA ARM OS. So gaming and general usage out of the window.\n\n  \nAlso Sparks price \"Starting up $2999\" good luck finding one for below $3700. Can have 2 Framework 395 128GB bare bones for that money \ud83d\ude44",
            "score": 53,
            "replies": [
                {
                    "author": "sofixa11",
                    "body": ">the overpriced Framework Desktop 395 128GB is $1000 cheaper for similar bandwidth. The expected miniPCs from several vendors even cheaper than the Framework Desktop.\n\nWhy overpriced? Until there is anything comparable (and considering there's a PCIe slot there, most miniPCs won't be) at a lower price point, it sounds about right for the CPU.",
                    "score": 16,
                    "replies": [
                        {
                            "author": "Rich_Repeat_22",
                            "body": "The PCIe slots is PCIe1. Doesn't have Oculink so have to buy a M.2 to Oculink adaptor to hook a GPU.  The GMK X2 and the HP Z both have Oculink and USB4C.\n\n  \nPrise wise is similar to the Asus hybrid laptop/tablet, which is coming with monitors etc.",
                            "score": -1,
                            "replies": [
                                {
                                    "author": "noiserr",
                                    "body": " Is it though? Are you looking at the 128GB version? Framework Desktop starts at 1,099.00 for the 32GB version.",
                                    "score": 2,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Haiart",
                    "body": "It'll likely sell merely because it has the NVIDIA logo in it.",
                    "score": 14,
                    "replies": [
                        {
                            "author": "Rich_Repeat_22",
                            "body": "Not these days.",
                            "score": 1,
                            "replies": []
                        },
                        {
                            "author": "nderstand2grow",
                            "body": "at this point the Nvidia brand is so bad that it will actually not sell because it has the Nvidia brand on it",
                            "score": -6,
                            "replies": [
                                {
                                    "author": "Inkbot_dev",
                                    "body": "I'm wondering why you think their brand is so damaged? \n\nLegitimate question, not a gotcha.",
                                    "score": 7,
                                    "replies": [
                                        {
                                            "author": "nderstand2grow",
                                            "body": "look up missing RPOs, burning sockets, GPUs never available at MSRP, false advertising (Jensen comparing 4090 with 5070 whereas 4090 still blows 5070 out of the water), disabling nv-link on 4090 to push people to buy their enterprise grade GPUs (+$15000), disabling features by pushing driver updates (e.g., no bitcoin mining possible even though the GPU can - and used to be able to - technically do it), etc.\n\ntl;dr: nvidia are enjoying their monopoly, they hype up the AI market for stonks, and while they create some value (the GPUs), their greedy marketing and pricing is going to cause them trouble in long term.",
                                            "score": 6,
                                            "replies": []
                                        },
                                        {
                                            "author": "Healthy-Nebula-3603",
                                            "body": "Really.\n\nHave you seen how bad are Rtx 5070 or 5060 ....people are not happy at all ...overpriced only .",
                                            "score": 4,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Medical-Ad4664",
                    "body": "how is playing games on it even remotely a factor wtf \ud83d\ude02",
                    "score": 7,
                    "replies": [
                        {
                            "author": "Rich_Repeat_22",
                            "body": "huh? Ignorance is bliss? \ud83e\udd14\n\nAMD 395 120W has iGPU equivalent to desktop 4060Ti (tad faster than the Radeon 6800XT), with \"unlimited\" VRAM. While the CPU is a 9950X with access to memory bandwidth equivalent to 6-channel DDR5-5600 found in Threadripper platform. \n\nIs way faster than 80% of the systems found on Steam Survey.",
                            "score": 3,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "unixmachine",
                    "body": ">Contrary to Spark which is limited to the specialised NVIDIA ARM OS.\n\nDXG OS is just Ubuntu with optimized Linux kernel, which supports GPU Direct Storage (GDS) and access to all NVIDIA GPU driver branches and CUDA toolkit versions.",
                    "score": 5,
                    "replies": [
                        {
                            "author": "Rich_Repeat_22",
                            "body": "ARM Ubuntu.... And that matters if want to do more with the machine.",
                            "score": 2,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Conscious-Tap-4670",
                    "body": "Only the $4k variant of the DGX spark is even available right now",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "Bolt_995",
            "body": "Can\u2019t wait to see the performance comparison with this against the new Mac Studio.",
            "score": 20,
            "replies": []
        },
        {
            "author": "Healthy-Nebula-3603",
            "body": "273 GB/s ?\n\nLol \n\n\nNot worth it.\nIs 1000% better to buy M3/M4 ultra or max",
            "score": 10,
            "replies": []
        },
        {
            "author": "Haiart",
            "body": "LMFAO, this is the fabled Digits people were hyping over for months? Why would anyone buy this? Starting at $3000, the most overpriced 395 is $1000 less than this, not even mentioning Apple silicon or the advantages of the 395 that can run Windows/Linux and retain the gaming capabilities.",
            "score": 23,
            "replies": [
                {
                    "author": "wen_mars",
                    "body": "With only 273 GB/s memory bandwidth I'm definitely not buying it. If it had >500 GB/s I might have considered it.",
                    "score": 3,
                    "replies": []
                }
            ]
        },
        {
            "author": "ForsookComparison",
            "body": "- Much cheaper for running 70gb - 200 gb models than a 5090\n\n- costs $3k\n\nThe 5090 is not it's competitor. Apple products run laps around this thing",
            "score": 40,
            "replies": [
                {
                    "author": "segmond",
                    "body": "Do you know what's even cheaper?  P40s.  9 yrs old, 347.1/GB/s   I have 3 of them that I bought for $450 total in the good ol days.    Is this progress or extortion?",
                    "score": 8,
                    "replies": [
                        {
                            "author": "ForsookComparison",
                            "body": "Oh you can get wacky with old hardware. There's $300 Radeon VII's by me that work with Vulkan Llama CPP and have 1TB/s memory.\n\nI'm only considering small footprint devices",
                            "score": 10,
                            "replies": [
                                {
                                    "author": "segmond",
                                    "body": "I'm not doing the theoretical, I'm just talking practical experience. I'm literally sitting next to ancient $450 GPUs that can equals a $3000 machine at running a 70B model.   Can't believe the cyberpunk future we saw in TV shows/animes are true, geeks with their old clobbered together rigs from ancient abandoned corporate hardware...",
                                    "score": 9,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "eleqtriq",
                    "body": "How does it run laps around this?  The Ultra inference scores were disappointing, especially time to first token.",
                    "score": 2,
                    "replies": [
                        {
                            "author": "ForsookComparison",
                            "body": "Are you excited to run 100GB contexts at 250GB/s best case? I'm not spending $3K for that",
                            "score": 5,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Terminator857",
                    "body": "Can you explain further?",
                    "score": -2,
                    "replies": [
                        {
                            "author": "buff_samurai",
                            "body": "Mac studio m3 ultra with .5T GB ram.",
                            "score": 10,
                            "replies": [
                                {
                                    "author": "Terminator857",
                                    "body": "How much does that cost?",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "author": "taylorwilsdon",
                                            "body": "$3500 for the m4 max 128gb so 500 bucks more buys you 546GB/s memory bandwidth and a computer that\u2019s useful for other things if one so desires",
                                            "score": 25,
                                            "replies": [
                                                {
                                                    "author": "eleqtriq",
                                                    "body": "But the inference scores sucked.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "author": "taylorwilsdon",
                                                            "body": "I have one (with smaller vram) no complaints. 15-20 tokens per sec is more than usable and that\u2019s worst case with a big model. Also have a nvidia gpu rig the only time you don\u2019t want a mac is training or multi user scenarios but for personal inference you\u2019re all gravy.",
                                                            "score": 2,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        },
                                        {
                                            "author": "AbdelMuhaymin",
                                            "body": "I asked Grok3:\nI assume you\u2019re asking about the price of a Mac Studio with an M3 Ultra chip and 0.5TB (512GB) of RAM. Based on the latest information available as of March 18, 2025, here\u2019s the breakdown:\n\nThe base model Mac Studio with the M3 Ultra chip starts at $3,999 in the US. This configuration includes a 28-core CPU, 60-core GPU, 32-core Neural Engine, 96GB of unified memory (RAM), and 1TB of SSD storage.\n\nTo upgrade to 512GB of RAM, which is the maximum unified memory option for the M3 Ultra, you\u2019d need to add that to the base configuration. According to Apple\u2019s pricing structure:\n\n- Upgrading from 96GB to 512GB of unified memory typically costs an additional $5,500.\n\nSo, starting from the base price of $3,999 and adding the $5,500 for 512GB of RAM, the total cost would be:\n\n**$3,999 + $5,500 = $9,499**\n\nThis assumes you keep the storage at 1TB. If you also want to adjust the SSD storage (e.g., to a different capacity like 512GB or higher), that would affect the price further:\n\n- Downgrading storage isn\u2019t an option below 1TB for the M3 Ultra model, but upgrading to, say, 2TB adds $400, 4TB adds $1,000, 8TB adds $2,200, or 16TB adds $4,600.\n\nFor a Mac Studio M3 Ultra with 512GB of RAM and the base 1TB SSD, the price is **$9,499**. If you meant something different by \u201c.5T GB\u201d (like a specific storage size), please clarify, and I can adjust the calculation! Prices may vary slightly depending on region, taxes, or promotions, so checking Apple\u2019s official website for your location would confirm the exact cost.",
                                            "score": -6,
                                            "replies": [
                                                {
                                                    "author": "comment0freshmaker",
                                                    "body": "Why are you getting downvoted?",
                                                    "score": 2,
                                                    "replies": [
                                                        {
                                                            "author": "Terminator857",
                                                            "body": "I upvoted, but I'm guessing people mechanically down vote chatbot responses.",
                                                            "score": 1,
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "AbdelMuhaymin",
                                                            "body": "Don't know. Weird.",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "fallingdowndizzyvr",
                                                    "body": "> The base model Mac Studio with the M3 Ultra chip starts at $3,999 in the US.\n\nIt's already on sale for $3400.\n\n> For a Mac Studio M3 Ultra with 512GB of RAM and the base 1TB SSD, the price is $9,499.\n\nEDU pricing knocks 10% off of that. Since Apple doesn't do verification for EDU pricing, anyone can get EDU pricing.",
                                                    "score": 1,
                                                    "replies": []
                                                },
                                                {
                                                    "author": "Terminator857",
                                                    "body": "Thanks!  In other words there is no comparison with the spark $3K versus m3 ultra with .5 TB at $10K.",
                                                    "score": -1,
                                                    "replies": [
                                                        {
                                                            "author": "hainesk",
                                                            "body": "Unless you decided to get 4 sparks so you can have 512GB of RAM. If you could run them in parallel, then theoretically the sparks would be slightly more expensive and slightly faster (assuming near perfect scaling).\n\nEditing to add: They have 4 USB 4 ports at 40Gb/s. You only need 3 ports on each to connect 4 of these together in a sort of mesh.",
                                                            "score": 9,
                                                            "replies": []
                                                        },
                                                        {
                                                            "author": "fightingCookie0301",
                                                            "body": "The Apple competitor actually wouldn\u2019t be the MacStudio with the M3 Ultra but a M3 Max. In the us you could get it for 3499$ (without tax) and also get 128GB RAM, but also MacOS and the whole Apple Infrastructure.\n\nBut at this point I\u2019d get 2x Framework desktop barebones and a rack for this money\u2026",
                                                            "score": 0,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "WackyConundrum",
            "body": "\"Cost 3k\" \u2014 yeah, right. 5090 was supposed to be 2k and we know how it turned out...",
            "score": 12,
            "replies": []
        },
        {
            "author": "Spare-Abrocoma-4487",
            "body": "They can keep it with themselves. No one needs such shitty mem bw.",
            "score": 14,
            "replies": []
        },
        {
            "author": "tyb-markblaze82",
            "body": "DGX Station link here also but no price tag yet, [https://www.nvidia.com/en-gb/products/workstations/dgx-station/](https://www.nvidia.com/en-gb/products/workstations/dgx-station/)",
            "score": 5,
            "replies": [
                {
                    "author": "Mr_Finious",
                    "body": "https://preview.redd.it/10rwnv0f9ipe1.png?width=1826&format=png&auto=webp&s=9892ee8f560551a3b2e76556bca7b1c9de075b45\n\nSpecs look a bit better than the Spark.",
                    "score": 4,
                    "replies": [
                        {
                            "author": "danielv123",
                            "body": "I am guessing $60k, I like being optimistic",
                            "score": 10,
                            "replies": [
                                {
                                    "author": "ROOFisonFIRE_usa",
                                    "body": "I hope they make it way more affordable than that. I appreciate what they have done. I will appreciate it even more if its not outrageously priced.",
                                    "score": 1,
                                    "replies": []
                                },
                                {
                                    "author": "tyb-markblaze82",
                                    "body": "i fed the specs to perplexity and went low with a 10k price tag just to get its opinion, heres what it said lol:\n\n\"Your price estimate of over $10,000 is likely conservative. Given the high-end components, especially the Blackwell Ultra GPU and the substantial amount of HBM3e memory, the price could potentially be much higher, possibly in the $30,000 to $50,000 range or more\"\n\nyoull save the 10k i originally started with so your good man, only one of your kids need a degree :)",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "Healthy-Nebula-3603",
                            "body": "If such a device would cost 3k ...",
                            "score": 4,
                            "replies": []
                        },
                        {
                            "author": "tyb-markblaze82",
                            "body": "im not good at hardware stuff but how does the different memory work? it reminds me of the gtx 970 4GB/3.5GB situation",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "MammothInvestment",
            "body": "Does anyone think the custom nvidia os will have any optimizations that can  give this better performance even with the somewhat limited bandwidth?",
            "score": 4,
            "replies": [
                {
                    "author": "Calcidiol",
                    "body": "IDK.  Nvidia has the tensorrt stuff for accelerating inference via various possibly useful optimizations of the inference configuration but I am not sure how their accelerator architecture here could benefit from various possible inference optimizations and yet not end up RAM BW bottlenecked to a level that makes some such irrelevant.\n\nCertainly for things like speculative decoding or maybe even batching to some extent etc. one could imagine having some faster / big enough cache RAM or what not could help small iterated sections of model inference be less RAM BW bottlenecked due to some opportunities to reuse cache / avoid repetitive RAM reads.  But IDK what the chip architecture and sizing of cache and resources other than RAM are for this.\n\nAnyway that's not really OS level stuff, more \"inference stack and machine architecture\" level stuff.  At the OS level?  Eh I'm not coming up with many optimizations that get around RAM BW limits though one could certainly mess up optimization of anything with bad OS configuration.\n\nI suppose if one clusters machines then the OS and networking facilities could optimize that latency / throughput.",
                    "score": 3,
                    "replies": []
                },
                {
                    "author": "__some__guy",
                    "body": "Yes, but memory bandwidth is a hard bottleneck that can't be magically optimized away.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "Belnak",
            "body": "The Founders Edition is listed at $3999. They\u2019re also offering the 128Gb Asus Ascent GX10 for $2999.",
            "score": 5,
            "replies": []
        },
        {
            "author": "Ulterior-Motive_",
            "body": "I'm laughing my ass off, Digits got all the press and hype but AMD ended up being the dark horse with a similar product for 50% less. Spark will be faster, but not $1000 faster LOL",
            "score": 5,
            "replies": [
                {
                    "author": "OkAssociation3083",
                    "body": "does ADM has something with CUDA that can help with image gen, video gen and has like 64 or 128gb memory in case I also want to use a local llm?",
                    "score": 3,
                    "replies": [
                        {
                            "author": "noiserr",
                            "body": "AMD experience on Linux is great. The driver is part of the kernel so you don't even have to worry about it. ROCm is getting better all the time, and for local inference I've been using llamacpp based tools like Kobold for over a year with no issues.\n\nROCm has also gotten easier to install, and some distros like Fedora have all the ROCm packages in the distro repos so you don't have to do anything extra. Perhaps define some env variables and that's it.",
                            "score": 1,
                            "replies": []
                        },
                        {
                            "author": "avaxbear",
                            "body": "Nope that's the downside to the cheaper amd products. And is cheaper for inference (local LLM) but no cuda.",
                            "score": 0,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "AliNT77",
            "body": "Isn\u2019t this just a terrible value compared to mac studio? I just checked mac studio m4 max 128gb and it costs 3150$ with education pricing\u2026 and the memory bandwidth is exactly double at 546GB/s\u2026",
            "score": 4,
            "replies": [
                {
                    "author": "Ok_Warning2146",
                    "body": "Yeah for the same price, why would anyone not go for m4 max 128gb?",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "fallingdowndizzyvr",
            "body": "I rather have a Strix Halo for almost half the price.",
            "score": 10,
            "replies": []
        },
        {
            "author": "cobbleplox",
            "body": "So Cuda is basically the only point of this, and I doubt many of us need that.",
            "score": 3,
            "replies": []
        },
        {
            "author": "-6h0st-",
            "body": "Went to reservation page and it states DXG spark FE for 4k. \n4k for 128GB ram at 273GB/s? Hmm I think I\u2019ll get M4 Max with 128GB and it will run at 576GB/s for less plus a useful computer at the same time no?",
            "score": 3,
            "replies": [
                {
                    "author": "noiserr",
                    "body": "Or the Framework Desktop Strix Halo for like $2100. And not only can you run a usable OS, you can also play games on it.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "grim-432",
            "body": "Apple did it better",
            "score": 20,
            "replies": [
                {
                    "author": "None",
                    "body": "[deleted]",
                    "score": -4,
                    "replies": [
                        {
                            "author": "nonerequired_",
                            "body": "Downvoted for not searching at all",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "jdprgm",
            "body": "this is fucking bullshit. i'm not really surprised as why would nvidia compete with themselves when they are just printing money with their monopoly. that being said can somebody just build a fucking machine with 4090 levels of compute, 2 TB/s mem bandwidth and configurable unified memory priced at like $2500 for 128gb.",
            "score": 8,
            "replies": [
                {
                    "author": "Charder_",
                    "body": "Only apple has usable ARM APUs for work and AMD still needs to play catchup with their APUs in terms of bandwidth. Nvidia doesn't have anything usable for consumers yet. None of these machines will be at the price you wish for either.",
                    "score": 3,
                    "replies": [
                        {
                            "author": "Healthy-Nebula-3603",
                            "body": "AMD has already better product than that Nvidia shit and 50% cheaper .",
                            "score": 2,
                            "replies": [
                                {
                                    "author": "OkAssociation3083",
                                    "body": "but most software was coded with CUDA in mind, so that's an issue when trying to run certain video gen, tts or image gen :(  \nso, AMD is not an option unless the software will also take that into account. That's the current situation, almost everything wants CUDA",
                                    "score": 1,
                                    "replies": []
                                },
                                {
                                    "author": "Charder_",
                                    "body": "Did you reply to me by accident or read my message too fast?",
                                    "score": 0,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "notlongnot",
                    "body": "The entry level H100 using HBM3 memory has about 2TB/s bandwidth and 80GB of VRAM. $20K range on eBay. \n\nLower processing power with faster memory at reasonable price will take some patience waiting...",
                    "score": 3,
                    "replies": []
                }
            ]
        },
        {
            "author": "dobkeratops",
            "body": "for everyone saying this is trash.. (273gb/sec dissapointment)\n\nwhat's this networking that it has .. \"ConnectX 7\" I see specs like 400Gb/s I presume thats bits, if these pair up with 50 gigabytes/sec of bandwidth between boxes , it might still have a USP. It mentions pairing them up , but what if they can also be connected to a fancy hub?\n\napple devices & framework seem more interesting for LLMs\n\nbut this will likely be a lot faster at diffusion models (those are very slow on apple hardware as far as I've tried and know)\n\nAnyway from my POV at least I can reduce my Mac Studio Dither-o-meter.",
            "score": 3,
            "replies": []
        },
        {
            "author": "5dtriangles201376",
            "body": "What makes this more than like 7% better than the framework desktop? Prompt processing?",
            "score": 6,
            "replies": [
                {
                    "author": "Imaginary_Total_8417",
                    "body": "Nvidia Stack",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "Vb_33",
            "body": "DGX Sparks (formerly Project DIGITS). A power-efficient, compact AI development desktop allowing developers to prototype, fine-tune, and inference the latest generation of reasoning AI models with up to 200 billion parameters locally.\u00a0\n\n\n* 20 core Arm, 10 Cortex-X925 + 10 Cortex-A725 Arm\u00a0\n\n\n* GB10 Blackwell GPU\n\n\n* 256bit 128 GB LPDDR5x, unified system memory, 273 GB/s of memory bandwidth\u00a0\n\n\n* 1000 \"AI tops\", 170W power consumption\n\n\n\n\nDGX Station: The ultimate development, large-scale AI training and inferencing desktop.\n\n\n* 1x Grace-72 Core Neoverse V2\n\n\n* 1x NVIDIA Blackwell Ultra\n\n\n* Up to 288GB HBM3e | 8 TB/s GPU memory\u00a0\n\n\n* Up to 496GB LPDDR5X | Up to 396 GB/s\u00a0\n\n\n* Up to a massive 784GB of large coherent memory\u00a0\n\n\n\n\nBoth Spark and Station use DGX OS.\u00a0",
            "score": 2,
            "replies": [
                {
                    "author": "oh_my_right_leg",
                    "body": "Price for the station?",
                    "score": 2,
                    "replies": []
                },
                {
                    "author": "Ok_Warning2146",
                    "body": "It would be great if there is another product between Spark and Station.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "BumbleSlob",
            "body": "> Memory Bandwidth 273 GB/s\n\nhttps://i.imgflip.com/9nbe1w.jpg",
            "score": 3,
            "replies": []
        },
        {
            "author": "s3bastienb",
            "body": "That's pretty close to the framework desktop at 456GB/s. I was a bit worried i made a mistake pre-ordering  the framework. I feel better now, save close to $1k and not much slower.",
            "score": 2,
            "replies": [
                {
                    "author": "fallingdowndizzyvr",
                    "body": "> That's pretty close to the framework desktop at 456GB/s. \n\nFramework is not 456GB/s, it's 256GB/s.",
                    "score": 13,
                    "replies": [
                        {
                            "author": "noiserr",
                            "body": "Both digits and strix halo have the same memory bus, so similar bandwidth basically. I doubt there will be much difference at all in performance.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "codingworkflow",
            "body": "Nvidia margins are higher than apple now. So what did you expect?",
            "score": 1,
            "replies": []
        },
        {
            "author": "Mobile_Tart_1016",
            "body": "273GB/s????????????",
            "score": 1,
            "replies": []
        },
        {
            "author": "eredhuin",
            "body": "Price point in the wait list is $3999 btw - \"Founder's Edition\" 4TB Spark",
            "score": 1,
            "replies": []
        },
        {
            "author": "spiffco7",
            "body": "Excellent price for access to NIM",
            "score": 1,
            "replies": []
        },
        {
            "author": "noiserr",
            "body": "Glad I ordered the Framework Desktop, Batch #2.",
            "score": 1,
            "replies": []
        },
        {
            "author": "siegevjorn",
            "body": "So, a $3000 M4 Pro Mac mini 128GB, huh?",
            "score": 1,
            "replies": []
        },
        {
            "author": "drdailey",
            "body": "Major letdown with that low memory bandwidth.  The dgx station is the move. If that is the release memory bandwidth this thing will be a dud. Far less performant than apple silicon.",
            "score": 1,
            "replies": []
        },
        {
            "author": "divided_capture_bro",
            "body": "Cost is $3999 according, or $8049 for two with a chord.",
            "score": 1,
            "replies": []
        },
        {
            "author": "The_Hardcard",
            "body": "It\u2019ll be fun to watch these race the Mac Studios. The Sparks will already have generated many dozens of tokens while the Macs are still processing the prompt, then we can take bets on whether the Macs can overtake the lead once they start spitting tokens.",
            "score": 1,
            "replies": []
        },
        {
            "author": "__some__guy",
            "body": "Useless and overpriced for that little memory bandwidth.\n\nAMD unironically is the better choice here.\n\nI'm glad I didn't wait for this shit.",
            "score": 1,
            "replies": []
        },
        {
            "author": "LiquidGunay",
            "body": "For all the machines in the market there always seems to be a tradeoff between compute , memory and memory bandwidth. The M3 Ultra has low FLOPS, the RTX series (and even an H100) has low VRAM and now this has low memory bandwidth.",
            "score": 1,
            "replies": []
        },
        {
            "author": "tyb-markblaze82",
            "body": "ill probably just wait for real world comparison benchmarks and consumer adoptation then deiced if spark/mac or Max+ 395 suits me. One thing im thinking is that only 2 DGX Spark can be coupled whereas you could stack as many macs or Framework Desktops etc together",
            "score": 1,
            "replies": []
        },
        {
            "author": "BenefitOfTheDoubt_01",
            "body": "Can someone help me understand the hardware here.\n\nAs far as I thought this worked, if someone is generating images, this would rely on GPU VRAM, correct? \n\nAnd if someone is running a chat, this relies more on RAM and the more RAM you have the larger the model you can run, correct? \n\nBut then there are some systems that share or split RAM making it act more like VRAM so it can be used for functions that rely more on VRAM such as image generation , is this right? \n\nAnd which functions would this machine be best used for and why? \n\nThanks folks!",
            "score": 1,
            "replies": []
        },
        {
            "author": "anonynousasdfg",
            "body": "So a Mac mini m4 pro 64gb looks like a more affordable and a better option if you aim to run just <70B models with a moderate context size, as their memory bandwidths are the same, yet mlx architecture is better optimized than gguf. What do you think?",
            "score": 1,
            "replies": [
                {
                    "author": "SpecialistNumerous17",
                    "body": "That's what I'm doing",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "AbdelMuhaymin",
            "body": "Can anyone here answer me if this DGX Spark will work with Comfyui and generative art and video? Wan 2.1 really loves 80GB of vram and cudas. So, would DGX work with that too. I'm genuinely curious. If so, this is a no-brainer. I'll buy it day one.",
            "score": 1,
            "replies": [
                {
                    "author": "Healthy-Nebula-3603",
                    "body": "Bro that machine will be X4 slower even rtx 3090 ....",
                    "score": 5,
                    "replies": []
                }
            ]
        },
        {
            "author": "Majinsei",
            "body": "How much it's the main difference in tokens/seconds between DGX Spark and M\u00faltiple GPUs? (Ignoring money)\n\nIt's 20% more slower or 80%? 2 tokens/seg?",
            "score": 1,
            "replies": [
                {
                    "author": "AllanSundry2020",
                    "body": "buy Appel sell NiVidia",
                    "score": 4,
                    "replies": [
                        {
                            "author": "Majinsei",
                            "body": "???",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "unixmachine",
            "body": "The comparisons with the Framework are kind of pointless. The DGX Spark GPU is at least 10x superior. One point that can get around the bandwidth that I found interesting is that DXGOS is an Ubuntu with a modified kernel that has Direct Storage, which allows data exchanges directly between the GPU and the SSD.",
            "score": 1,
            "replies": [
                {
                    "author": "Terminator857",
                    "body": "\\> GPU is at least 10x superior\n\nSource?",
                    "score": 1,
                    "replies": [
                        {
                            "author": "unixmachine",
                            "body": "The DGX Spark specs point to a Blackwell GPU with 1000 TOPS FP4 (seems similar to the 5070), while the Ryzen AI 395 achieves 126 TOPs.\nI think the comparison is bad, because while one is an APU for laptops, the other is a complete workstation with super fast network connection. This is to be used in a company lab.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "the320x200",
                    "body": "If you're reading out of the SSD to the GPU for LLMs you're already cooked.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "EstebanGee",
            "body": "That\u2019s the wordle word for the day. Coincidence?",
            "score": -3,
            "replies": []
        }
    ]
}