{
    "title": "Open source 7.8B model beats o1 mini now on many benchmarks",
    "author": "TheLogiqueViper",
    "subreddit": "LocalLLaMA",
    "rank": 16,
    "score": 237,
    "upvote_ratio": 0.87,
    "num_comments (reported by reddit)": 92,
    "url": "https://i.redd.it/211jtna16fpe1.jpeg",
    "id": "1je17el",
    "selftext": "",
    "comments": [
        {
            "author": "inagy",
            "body": "Are any of these benchmarks still trustworthy enough though? I mean, obviously most of these LLM vendors will try to look good in them, so who stops them from intentionally training their models to excell on these?\n\nI think you cannot escape the need to validate these claims with your own use case, unfortunately.",
            "score": 174,
            "replies": [
                {
                    "author": "FluffnPuff_Rebirth",
                    "body": "Only benchmark I trust is me trying out the model and then going with the vibes and gut feels. Utilizing the low-level systems of my neural network, aka intuition, so to speak. Memes aside, intuition and personal experience are the gold standard for benchmarking subjective criteria like \"Do I like this\".\n\nBut sadly such benchmarking methodology is also very time consuming to perform at scale which is why we have these attempts at objective benchmarks to begin with. Where was I going with all of this? Started internally rambling there like a CoT model, but at least I didn't do it for 3000 tokens.",
                    "score": 54,
                    "replies": [
                        {
                            "author": "No_Afternoon_4260",
                            "body": "Lol seems like your neural net just wandered around",
                            "score": 16,
                            "replies": [
                                {
                                    "author": "EducatorThin6006",
                                    "body": "Hi neural networks. Your parents did a fine job finetuning you all for good mannerisms.",
                                    "score": 7,
                                    "replies": [
                                        {
                                            "author": "No_Afternoon_4260",
                                            "body": "Hahaha I'll reward them so they continue doing a better job each epochs",
                                            "score": 4,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "s101c",
                            "body": "Have your own set of usecases, test them **locally only** and never share with the external world.",
                            "score": 4,
                            "replies": []
                        },
                        {
                            "author": "Over-Independent4414",
                            "body": "The acid test is whether it can do things that are useful in the real world. Having a chat with it and feeling like it was fun is, OK, but that gets boring very fast. The enduring test is can it make your actual day-to-day life, better.\n\nSo far, for me, after trying a LOT of models, it's only OpenAI's deep research and Claude 3.7 that I can say that about. The rest are, for me, fun toys but not much else.\n\nAnd yes, there is no \"official\" test that would capture WHY these are useful to me in the real world. Claude, for whatever reason, is fantastic at understanding a situation and making flowcharts out of it, this helps me at work consistently. There's also no benchmark for qualitative analysis but that's where OAI's deep research excels in a way that's next level above any other tool (however still with suspected hallucinations).\n\nSo, part vibe but also part about whether it's useful beyond just having some witty repartee.",
                            "score": 4,
                            "replies": []
                        },
                        {
                            "author": "TheRealGentlefox",
                            "body": "Exactly. I can get the vibe down after a good amount of time, but not only is it annoying, I'm not going to switch off my daily driver and get worse advice just for testing out a new model.\n\nPersonally I wish we had more private benchmarks with public results.",
                            "score": 2,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "CodNo7461",
                    "body": "Yeah. This mostly only tells me that if I ever have a very specific task which a big general LLM does well, I can train my 10 times smaller model to do that specific task roughly as well. Which is still neat, but you know, often not as good as it sounds.",
                    "score": 7,
                    "replies": []
                },
                {
                    "author": "atomwrangler",
                    "body": "Especially on self reported benchmarks on distilled models.  In that case I think external validation on additional benchmarks can help clear it up.  At 8b it seems impossible they aren't overfit...",
                    "score": 1,
                    "replies": [
                        {
                            "author": "SporksInjected",
                            "body": "O1-mini is also a small parameter model though. It\u2019s not far fetched to believe that two 8b models benchmark the same.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "hudimudi",
            "body": "Benchmarks are dead to me. They never compare to the quality of a model regarding real world use cases.",
            "score": 107,
            "replies": [
                {
                    "author": "umataro",
                    "body": "But then how else will microsoft get people to download its Phi4?",
                    "score": 21,
                    "replies": [
                        {
                            "author": "JLeonsarmiento",
                            "body": "I\u2019ve just downloaded phi4 mini again (3rd time) this morning\u2026 and it is finally working as intended in cli.",
                            "score": 9,
                            "replies": [
                                {
                                    "author": "skyde",
                                    "body": "What did you do differently this time ?",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "author": "JLeonsarmiento",
                                            "body": "I think it has something to do with the ollama version that was released this last Saturday. \n\nNo more brain damaged phi-mini.",
                                            "score": 3,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "EggplantFunTime",
                    "body": "Exactly. What stops model developers from including benchmark datasets in their training data? And how can we tell if they did?\n\nhttps://en.m.wikipedia.org/wiki/Goodhart%27s_law",
                    "score": 3,
                    "replies": [
                        {
                            "author": "Over-Independent4414",
                            "body": "Nothing and you probably can't tell if they did. I'm not so sure even THEY know if they trained on benchmarks. There are some evolving benchmarks that are meant to turn over a lot so it's very unlikely the model was trained on it.\n\nCoding competitions probably still have value. All the frontier labs have said they will saturate the benchmarks and i think that's partially improvements and partially being trained on every benchmark ever made.",
                            "score": 2,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "sigjnf",
            "body": "Isn't the LG model far from open-source?\n\n*\"Here's a brief summary of the EXAONE AI Model License Agreement:*\n\n* *Model can only be used for research purposes - no commercial use allowed at all (including using outputs to improve other models)*\n* *If you modify the model, you must keep \"EXAONE\" at the start of its name*\n* *Research results can be publicly shared/published*\n* *You can distribute the model and derivatives but must include this license*\n* *LG owns all rights to the model AND its outputs - you can use outputs for research only*\n* *No reverse engineering allowed*\n* *Model can't be used for anything illegal or unethical (like generating fake news or discriminatory content)*\n* *Provided as-is with no warranties - LG isn't liable for any damages*\n* *LG can terminate the license anytime if terms are violated*\n* *Governed by Korean law with arbitration in Seoul*\n* *LG can modify the license terms anytime*\n\n*Basically, it's a research-only license with LG maintaining tight control over the model and its outputs.\"*\n\nComment by u/CatInAComa",
            "score": 65,
            "replies": [
                {
                    "author": "shyam667",
                    "body": "\\>*LG owns all rights to the model AND its outputs*  \n  \nOn my way to email all the chat-logs to LGcare.",
                    "score": 49,
                    "replies": [
                        {
                            "author": "windozeFanboi",
                            "body": "DO IT!",
                            "score": 8,
                            "replies": []
                        },
                        {
                            "author": "Josiah_Walker",
                            "body": "please tell be they include jailbreaks and nsfw RP",
                            "score": 3,
                            "replies": []
                        },
                        {
                            "author": "MrPecunius",
                            "body": "Waifu is gonna be *pissed*",
                            "score": 1,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Pedalnomica",
                    "body": "Another ~~open~~ visible weight license.",
                    "score": 10,
                    "replies": [
                        {
                            "author": "xor_2",
                            "body": "Sad but it is still like 1000 times better than what \"Open\"AI does with their models.",
                            "score": 5,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "conmanbosss77",
                    "body": "So then there's no real use for it, unless it's for research. I dont think it will be used over other local llms because of those terms.",
                    "score": 10,
                    "replies": [
                        {
                            "author": "sigjnf",
                            "body": "I will simply give no shit and do whatever I want with the model.",
                            "score": 31,
                            "replies": [
                                {
                                    "author": "logseventyseven",
                                    "body": "yeah I wonder how they would find out that I used code generated by it in my commercial project",
                                    "score": 10,
                                    "replies": [
                                        {
                                            "author": "xor_2",
                                            "body": "Code not, texts not, etc etc but if you were to create finetunes **and upload to HF** I am not sure this license allows that. Probably not. Even if you did full finetune and all weight changed you would still have tokenizer from their model which could be used to identify your model. By the time you made your own model you spent so much effort you could make something else... and we will have 7B QwQ\n\nThat said for personal use on smaller devices... yeah, who cares?",
                                            "score": 2,
                                            "replies": [
                                                {
                                                    "author": "g3t0nmyl3v3l",
                                                    "body": "Literally the second term in that license summary says if you modify the model (which fine tuning would fall under) then you have to still call it an exaone model.",
                                                    "score": 3,
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "frivolousfidget",
                            "body": "Even for research one wouldnt want a license that restrictive",
                            "score": 10,
                            "replies": []
                        },
                        {
                            "author": "RMCPhoto",
                            "body": "\"research\"",
                            "score": 3,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "JLeonsarmiento",
                    "body": "I\u2019m *researching * how good it is for commercial use. Is that ok?",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "nuclearbananana",
                    "body": "Totally fine for personal use. That's all I care about",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "nrkishere",
            "body": "Benchmarks are pointless. Every models these days are designed to be benchmark queens rather than being actually helpful. Ofcourse there are models which are still useful, but these graphs are quite deceptive",
            "score": 16,
            "replies": [
                {
                    "author": "xor_2",
                    "body": "Still you need to have strong benchmark performance to generate interest.\n\nAlso it is length measuring content.",
                    "score": 1,
                    "replies": [
                        {
                            "author": "nrkishere",
                            "body": "Benchmarks should be limited for quantitative matrices, not qualitative. Parameters like throughput/tps, memory consumption, context length are quantitative. There are many benchmarks that rank models based on things like programming, mathematics, creative writing etc., most of which are qualitative measures.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "ElephantWithBlueEyes",
            "body": "Tried questions from my old chats with gemma 3 and on first glance this model feels like it's on par with gemma 3 4b.\n\nI don't think benchmarks should be the case when comparing models. I think new way to compare models is to find out which one is less useless.",
            "score": 11,
            "replies": [
                {
                    "author": "Then_Knowledge_719",
                    "body": "\ud83d\udcaf",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "Mad_Undead",
            "body": "Devs: Pinky promise not to overfit\u00a0on\u00a0benchmark\u00a0data.",
            "score": 20,
            "replies": []
        },
        {
            "author": "hapliniste",
            "body": "For me the big news is that <3B models can scale a lot further.\n\nWhat I want is a vision model trained with grpo in an agentic ui environment. A 3B model would run super fast on edge devices so it makes reflection models viable for ui use, and it looks like it could perform very well in the next months.",
            "score": 7,
            "replies": [
                {
                    "author": "RMCPhoto",
                    "body": "Narrow 3b models for vaguely generalized tasks within a given domain would be amazing.\u00a0\u00a0\n\n\nAlso small models that handle instruction and context exceptionally well would be very useful.\u00a0 \u00a0\n\n\nThe problem with small models is that they have less \"knowledge\", which causes them to perform poor on novel tasks, or open ended tasks \"like writing\".\u00a0\u00a0\n\n\nTasks like tool use, evaluating images for certain features (included in context) etc would be great.\u00a0 \u00a0 Models with built with real intention to feed the knowledge in context in a specific format (definitions of terms, description of the problem, etc) is what I want to see more of.\u00a0 \u00a0\n\n\nA local llm should not be for \"fact answering without context\", they will never be large enough to be reliable, and the facts are outdated as soon as the model is trained.\u00a0 A local llm should be for processing context.\u00a0\u00a0",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "WackyConundrum",
            "body": "It's not Open Source when you don't get the source.",
            "score": 5,
            "replies": []
        },
        {
            "author": "a_beautiful_rhind",
            "body": "I think the bottom line is that people who don't use LLMs are still swayed by these numbers. People who do are not.",
            "score": 5,
            "replies": [
                {
                    "author": "ForsookComparison",
                    "body": "You can tell on X, Facebook, Instagram, etc exactly who these people are.\n\n*\"February ChatGPT fell to Deepseek and crashed the stock market. Today, this 7B iPhone model just shattered everything we knew abou-..\"* \n\nNo it did not",
                    "score": 9,
                    "replies": []
                }
            ]
        },
        {
            "author": "sunpazed",
            "body": "It\u2019s really nice to have very small reasoning models!! (2.4B and 7.8B). However in my work use-cases both models were overly verbose (over 20,000 tokens to reason) and failed nearly every task. The 32B model was much better, but not in the same class as QwQ-32B.",
            "score": 4,
            "replies": [
                {
                    "author": "Chromix_",
                    "body": "I've added `--dry-multiplier 0.1 --dry-allowed-length 3 --temp 0` for the 2.4B model and it usually concludes thinking within 5K tokens then and rarely hits the 8K limit that I'm currently running my tests with. Why temp 0 instead of 0.7 or so? Because it lead to [better results in my tests](https://www.reddit.com/r/LocalLLaMA/comments/1j3byj5/comment/mg7selr/).\n\n**\\[Edit\\]**  \nUpon further testing this seems highly task-specific and the ones that I've ran so far didn't trigger it. Yet for example when it tries to reason its way to picking the right answer for \"Size range of dust, which is regarded as health hazard\" it indeed uses excessive amounts of tokens for such kind of exercise.",
                    "score": 2,
                    "replies": [
                        {
                            "author": "sunpazed",
                            "body": "Thanks. Yes, I also tried tweaking the default parameters and while this reduces reasoning tokens, the models end up failing more consistently.",
                            "score": 2,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Then_Knowledge_719",
                    "body": "So. Useless and super restrictive. Well done!!!",
                    "score": 1,
                    "replies": [
                        {
                            "author": "sunpazed",
                            "body": "If this helps improve other small reasoning models for research purposes then it\u2019s a positive.",
                            "score": 2,
                            "replies": [
                                {
                                    "author": "Then_Knowledge_719",
                                    "body": "Definitely. Free / open source all day long \u2764\ufe0f",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Chromix_",
            "body": "A little bit of context regarding that benchmark graph: QwQ beats EXAONE on AIME 2024 in a normal run (solid color in the graph). When making 64 runs per test and doing a majority vote on each exercise task then EXAONE scales better and gets a higher score (lighter color shade). That's costing a ton of thinking tokens though.\n\nWhen trained on ~~benchmarks~~ specifically crafted datasets a smaller model can catch up with the larger ones on some benchmarks. Yet GPQA Diamond and a few others still seem to be a domain where model size wins. That said, a 2.4B model scoring 53 on GPQA Diamond feels a little too high.\n\n**\\[Edit\\]**\n\nI've benchmarked the 2.4B model on the easy set of [SuperGPQA](https://www.reddit.com/r/LocalLLaMA/comments/1j3byj5/bytedance_unveils_supergpqa_a_new_benchmark_for/). The model is thinking a lot, maybe 5K tokens on average, more than 8K in 3% of the cases. It has a lot more trouble following the response format than the 1.5B R1 distill. I've now aborted after the score stabilized a bit at 31%. Qwen 1.5B scored 27.4, Qwen 3B scored 33.10 and 7B is 37.77. There's a miss rate of 5.4% where no answer in the correct format was found in the model output. If these were all correct answers (unlikely) it'd bump the model to a bit above 3B, yet still below 7B. These models are non-reasoning models that give a quick answer.\n\nThus, it seems unlikely that the 2.4B model would perform better than regular / reasoning tuned 7B models.",
            "score": 4,
            "replies": [
                {
                    "author": "DefNattyBoii",
                    "body": "Thanks for checking SuperGPQA! It seems to be a really comprehensive benchmark, i wonder why they dont use it as much. Did you use their own provided eval code from https://github.com/SuperGPQA/SuperGPQA ?",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "ElectricalHost5996",
            "body": "Has anyone tried it to see if they weren't optimized for benchmarking",
            "score": 3,
            "replies": [
                {
                    "author": "Lowkey_LokiSN",
                    "body": "I\u2019ve been experimenting with the 7.8B for some time and it\u2019s been genuinely amazing so far! If I did a blind test without knowing which model I\u2019m using: I would never believe that it\u2019s a 7.8B model\n\nI\u2019ve only tried questions concerning coding/math/tokenization so far and I cannot comment on its \u201cwell-roundedness\u201d yet\n\nSuch a bummer that their license sucks.",
                    "score": 4,
                    "replies": [
                        {
                            "author": "ElectricalHost5996",
                            "body": "Yeah but it kinda gives hope that you don't need expensive rigs to train or fine-tuning change the smaller models and still get a good results . The s1 paper about 1000 examples on 90$ budget to get really great results ,means we can tinker with smaller models or medium models and still get results comparable to some degree. There might still be lot of power in the smaller models we haven't yet explored",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "Lowkey_LokiSN",
                                    "body": "Yea! That\u2019s my key takeaway too. Really looking forward to the upcoming smaller releases after seeing a 7.8B model punching way above its weight .\nIt wouldn\u2019t take long for a 14B to outperform a QwQ 32B at this pace",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "RMCPhoto",
                            "body": "Any idea how it performs regarding structured output and instruction following?",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "Lowkey_LokiSN",
                                    "body": "I would rate it 6.5/10 as of now. Just for context, I'm running the LLM as an 8bit MLX quant\n\nIt handles basic stuff like creating a markdown table with requested data or generating a JSON file with custom data with ease.\n\nBut for more complex requests like [this prompt](https://www.jointakeoff.com/prompts/o1-pro-template-system-request-prompt), it does start struggling a bit to accurately address your new requests after multiple iterations.\n\nNeeds more testing overall but it's definitely usable.",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "fiery_prometheus",
                            "body": "Well, if you were motivated you could do a distillation of their model, sprinkle some other models in as well for deniability, and release your own license free model.\n\n\nIt seems that is the norm now for larger companies, so it's a legal grey area.",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "Lowkey_LokiSN",
                                    "body": "Think multiple companies are on it already and it's smart to just play the waiting game :)",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Scubagerber",
            "body": "Which one is best for coding? Asking for a friend.",
            "score": 3,
            "replies": [
                {
                    "author": "klam997",
                    "body": "realistically, and running local? definitely qwen 32b coder or QwQ 32b.\n\nusing an api? claude 3.7; cheaper option would be QwQ or R1",
                    "score": 2,
                    "replies": [
                        {
                            "author": "Scubagerber",
                            "body": "Ty",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "ihaag",
            "body": "Just as reliable as their TV\u2019s!",
            "score": 2,
            "replies": []
        },
        {
            "author": "TheLogiqueViper",
            "body": "Also 32B beats deepseek 671B on many benchmarks",
            "score": 3,
            "replies": []
        },
        {
            "author": "Empty-Tutor",
            "body": "Show me real results",
            "score": 1,
            "replies": []
        },
        {
            "author": "IrisColt",
            "body": "No.",
            "score": 1,
            "replies": []
        },
        {
            "author": "perelmanych",
            "body": "Even with the recommendations from their GitHub I couldn't make it think normally in LM Studio. Easy questions yes. A bit more elaborated that take more than 10k-15k tokens and it goes off the rails.",
            "score": 1,
            "replies": []
        },
        {
            "author": "DeepInEvil",
            "body": "Can't wait for the day when investors will lose interest in openai and we go back to solving business use-cases only using open-sourced solutions hosted in Azure or aws",
            "score": 1,
            "replies": []
        },
        {
            "author": "TechnicallySerizon",
            "body": "this seems to really work great I guess. It doesn't feel like reasoning. I gotta give it some real world problems now.",
            "score": 1,
            "replies": []
        },
        {
            "author": "AriyaSavaka",
            "body": "It's strange that they always leave out Aider Polyglot.",
            "score": 1,
            "replies": []
        },
        {
            "author": "hannibal27",
            "body": "I tested this model, both the 7B and the 32B versions, and they were dreadful in both language and results. It switched languages mid-text, altered basic information that even a small LLM could handle, and the 32B version went into a loop with a simple prompt: \"Talk about Brazil.\"  \nA bad model\u2014this kind of release only serves to erode trust in benchmarks, unfortunately.",
            "score": 1,
            "replies": []
        },
        {
            "author": "samelden",
            "body": "does any one now when i can test it without download it ?",
            "score": 1,
            "replies": [
                {
                    "author": "2catfluffs",
                    "body": "ollama: [https://ollama.com/omercelik/exaone-deep](https://ollama.com/omercelik/exaone-deep)",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "davidgyori",
            "body": "I feel like these benchmarks don\u2019t measure the practical capabilities of the models. I\u2019m still struggling to find a good open weight model to use with a langchain (I\u2019m experiencing a lot of hallucination, and weird behavior with structured outputs).\nMeanwhile, 4o-mini works like a charm.",
            "score": 1,
            "replies": [
                {
                    "author": "jhnnassky",
                    "body": "Did you try gemma 3 too?",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "LevianMcBirdo",
            "body": "Yeah of course AIME is easier when it's part of the training data. This can only be considered as a benchmark for the version it isn't trained on. (If at all)",
            "score": 1,
            "replies": []
        },
        {
            "author": "Rustybot",
            "body": "The only effective type of benchmark is one that the model developer doesn\u2019t know about. Otherwise it means very little. \n\nMy current favorite bench test is to ask a model to calculate the break even point for a small scale solar setup.",
            "score": 1,
            "replies": []
        },
        {
            "author": "m3kw",
            "body": "Who the f still uses o1 mini",
            "score": 1,
            "replies": []
        },
        {
            "author": "Professional-Bear857",
            "body": "I've tried the 7b model and so far the results are poor, even compared to other non thinking 7b models.",
            "score": 1,
            "replies": [
                {
                    "author": "AioliAdventurous7118",
                    "body": "Which other 7b models are you using?",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "cnmoro",
            "body": "Just tested the 7.8b one and it gave a complete nonsense answer on a python code that I asked for. Like, completely nonsense",
            "score": 1,
            "replies": []
        },
        {
            "author": "jeffwadsworth",
            "body": "Excited but extremely reserved to test this model out.  That claim in the title did give me a good belly-laugh though until it gets run through the ringer.",
            "score": 1,
            "replies": []
        },
        {
            "author": "h1pp0star",
            "body": "Give me a few minutes and my 3 yo daughter can doodle you a chart to prove she can code better than Claude 3.7 Thinking, it's completely legit and accurate because it's in a reddit post",
            "score": 1,
            "replies": []
        }
    ]
}