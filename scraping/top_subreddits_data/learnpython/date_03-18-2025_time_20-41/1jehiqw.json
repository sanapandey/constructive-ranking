{
    "title": "Sieve of Eratosthenes--Python Novice",
    "author": "Perturbed_CMDR",
    "subreddit": "learnpython",
    "rank": 7,
    "score": 2,
    "upvote_ratio": 1.0,
    "num_comments (reported by reddit)": 23,
    "url": "https://www.reddit.com/r/learnpython/comments/1jehiqw/sieve_of_eratosthenespython_novice/",
    "id": "1jehiqw",
    "selftext": "Hi all. I recently completed an introductory course in Python 3, and for sort of a palate cleanser before I move onto the intermediate course, I've been working my way through the first several problems on Project Euler.\n\nI've hit a wall with Problem 10. The problem asks for the sum of all prime numbers under two million.\n\nThe editors of Project Euler suggest that no problem on the site should take much more than one minute to solve by programming, largely irrespective of language.\n\nThe simplest logical approach, brute forcing the solution by compiling a list of primes by iterating through all the natural numbers up to 2000000 and checking each one for primacy, then finally summing that list. That strategy seems to work perfectly well up to about 300,000, but anything much higher than that seems to get things so internally gummed up as to effectively time out.\n\nI did some reading on the problem and rewrote my code to use the mathematical concept of the Sieve of Eratosthenes to achieve the list compilation more efficiently. Basically this winnows down an initial list of all the numbers up to the desired threshold by removing from the list all multiples of any list member. Without ever explicitly checking an integer for primacy, the Sieve gets rid of all composite numbers and leaves only primes behind.\n\nThe code I wrote functions as I expected it to and performs well, but, again, only to a certain magnitude. If I try to run it with the problem's given input of 2000000, the compiler runs indefinitely. I know it's still running because if I try to close the shell it warns me that doing so will interrupt execution. The longest I've sat there and waited for a return is an hour and ten minutes, then I finally killed it and decided to turn here for help.\n\nI'll post my code below. While any help at all is appreciated, what I want most is to understand how to solve this problem, in Python, using the Sieve of Eratosthenes method, without having to import anything at all, but just using what's available to the vanilla Python distribution/interpreter.\n\n    # PROBLEM 10 - Summation of Primes\n    # The sum of the primes below 10 is 2 + 3 + 5 + 7 = 17.\n    # Find the sum of all the primes below two million.\n    \n    def sieve_of_eratosthenes(upper_bound):\n        integer_list = list(range(3, upper_bound, 2))\n        current_position_index = 0\n        current_integer = integer_list[current_position_index]\n        def remove_multiples(prime_factor):\n            square_of_prime = prime_factor ** 2\n            for multiple_of_prime in range(square_of_prime, upper_bound, prime_factor):\n                if multiple_of_prime in integer_list:\n                    integer_list.remove(multiple_of_prime)\n        while current_integer ** 2 < upper_bound:\n            remove_multiples(current_integer)\n            current_position_index += 1\n            current_integer = integer_list[current_position_index]\n        return [2] + integer_list\n    \n    solution = sum(sieve_of_eratosthenes(2000000))\n    print(solution)\n    ",
    "comments": [
        {
            "author": "JeLuF",
            "body": "    if multiple_of_prime in integer_list:\n\nThis is a very slow operation on large lists. It will need to scan the entire list to check whether any element matches `multiple_of_prime`. This is O(n). And you do this n times, so you're at O(n\u00b2). \n\nConsider using an array of booleans instead of a list. Accessing an element in an array is O(1).",
            "score": 5,
            "replies": [
                {
                    "author": "thuiop1",
                    "body": "Or a set.",
                    "score": 5,
                    "replies": []
                },
                {
                    "author": "Perturbed_CMDR",
                    "body": "At the risk of discrediting myself for lack of fluency, does Python have a specific array datatype distinct from lists? I half-learned JS a decade ago and remember the array. When I went to start learning Python a few months back I always expected that arrays would be introduced, but they never were, and I assumed given all the similarities that lists were Python's equivalent to JS-style arrays.",
                    "score": 1,
                    "replies": [
                        {
                            "author": "JeLuF",
                            "body": "    integer_list[current_position_index]\n\nLists and arrays are different ways to use the same kind of object. In this line you are using the object as an array. You index it and have an O(1) access.\n\nThe `in` operator does a linear search through the entire array, and that's much slower than directly accessing an element.\n\nOthers have mentioned sets. These are lists that ensure that each element is unique, and to do so, they have fast ways to check whether an item is in the set or to remove an item. They behave very much like lists and you can keep your overall algorithm and just use a set instead of the list. [https://www.w3schools.com/python/python\\_sets\\_access.asp](https://www.w3schools.com/python/python_sets_access.asp)",
                            "score": 1,
                            "replies": []
                        },
                        {
                            "author": "ThySensFan",
                            "body": "Array functionality is provided by https://numpy.org/.",
                            "score": 0,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "incathuga",
            "body": "The main problem is that you're using list.remove() a lot, which behind the scenes is actually moving everything after the element that you remove. That means that if you remove the eighteenth element of integer\\_list, and the list has 750018 numbers in it at the moment, you have to shift 750000 elements. Each individual shift is quick enough, but you're shifting hundreds of thousands of elements hundreds of thousands of times, so you're looking at hundreds of millions of operations.\n\nThere are a few solutions here. One option (which I don't recommend, but it solves the particular issue I pointed out above) would be to switch to using linked lists, because removing elements of a linked list doesn't require moving later elements, but there are other problems -- another user pointed out the issue of scanning the entire list to find an element, and that's an issue with linked lists as well. (You could use a more complex data structure -- a binary tree has efficient searching and removal, so it might work out, but it's a bit more complex than you need here.) The other solution (which is probably better) is to stick with lists, and just change data rather than removing it. Since you're doing a sum at the end, replacing the entry with 0 is the same as removing that entry (as far as the solution is concerned, and more efficient in the intermediate steps). If that doesn't speed things up enough, think about how you can access only the multiples of whatever prime you're looking at, instead of scanning through the entire list for those multiples.",
            "score": 3,
            "replies": [
                {
                    "author": "Perturbed_CMDR",
                    "body": "I had no idea that the remove() functionality was also performing individual index shifts on everything after the element that gets removed. But if that's how it works, that certainly sounds sufficient to cause gridlock given how much lifting I have the remove() operation doing in my code. \n\nReplacing elements rather than removing them, with a 0 or False, feels like an elegant possible solution. Just to verify: changing the value of an element in a list is computationally more efficient than simply removing the element from the list?\n\nI appreciate your answer. You understood perfectly the sort of advice I'm looking for here.",
                    "score": 1,
                    "replies": [
                        {
                            "author": "incathuga",
                            "body": "Yes, changing the value of an element is computationally much faster than removing the element. Lists are stored as a consecutive block of memory, which is why accessing a list element via index is efficient -- the computer is actually going to the start of that memory block, and then jumping the appropriate amount of memory to reach that index. (This might not be perfectly accurate if you have a list of complex data structures, but it's at least approximately correct for a list of integers.) It's also why everything needs to be shifted when you delete an element, because if things don't shift you lose the nice \"the index is how far we need to jump\" property. But changing the element is just \"go to that location in memory and change the bits at that location, don't do anything to the rest of the block of memory\", so it's almost as fast as looking up the data.\n\nI'm glad that helped! Good luck with the rest of your learning.",
                            "score": 2,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "DrShocker",
            "body": "This is an excellent learning opportunity, and I'll try to offer more specific advice when I get to home with my laptop.\n\nHowever a first piece of advice I would offer is to add print/logging statements to make sure the execution flow is what you expect, and a second is to look into if your ide (if you're using one) can profile your code. Which is kind of a fancy term for having the computer tell you where your computer is spending a lot of time.\n\nThat said, I'm going to guess this is related to how lists work under the hood, and if that is the case I'll write up something to help you understand it. If that's not the case then obviously I'll try to help anyway, but just giving you that in case it's enough to get started.",
            "score": 1,
            "replies": [
                {
                    "author": "Perturbed_CMDR",
                    "body": "God, it'd be really helpful if you followed up on this comment. I typically do have logging statements throughout my code, I just took them out for cleanliness and readability before I posted here because, like I said, the code seems to function just as I intended/expected, and the print/logging tests confirmed as much, it's just getting hung up on any input past a certain order of magnitude.\n\nSo far, for the Euler problems, I've just been using the onboard IDE, IDLE, and intend to keep doing so until I have a pressing reason to change to something more bespoke. But anything you can tell me about IDE profiling or any other methods of 'gaming the computer' to give me insight as to what's so slow in particular would be hugely helpful. I'm so new to all of this that logging to the terminal is the closest I get to anything like debugging, which I recognize I could really use now.",
                    "score": 1,
                    "replies": [
                        {
                            "author": "DrShocker",
                            "body": "I'll be about 20 minutes or so, sorry, but it's hard for me to think about the code properly on my phone screen",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "Perturbed_CMDR",
                                    "body": "Take your time! I'd much prefer a thorough answer later on--my goal here is to really understand *why* whatever I did wrong was wrong to do in this specific instance.\n\nI really appreciate it. I was afraid I'd only get FTFY's for responses, if I got any.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "DrShocker",
                                            "body": "So my short answer is, I think that /u/[incathuga](https://www.reddit.com/user/incathuga/) is correct about what is likely the bulk of what the time of your program is being spent doing.\n\nI looked into how to profile without an IDE and found this: [https://docs.python.org/3/library/profile.html](https://docs.python.org/3/library/profile.html)\n\nWith a smaller input I found that very nearly all the time is spent in remove multiples. (side note, it technically works, but it's weird to declare functions inside the scope of another function unless you have a reason to.)\n\nso, I changed things a bit and tried changing to use filter instead of remove. That made it around 10x faster, so it's a fairly strong indication that it is indeed the problem area.\n\nOn my computer that made the whole thing run in less than a minute, so you could stop there  \n  \n, but if you look at /u/[incathuga](https://www.reddit.com/user/incathuga/) s comment you will see that basically there is a large hidden cost from when you remove just one element, you need to copy over all the other elements to a new array behind the scenes because the way a python list works every element must be nect to each other in memory.\n\nFor that reason, people's suggestions to just keep using extra memory to store an array with a bool for every value and just flip them to false. And convert them to numbers at the end. This has the advantage that you can directly access the elements, so you don't need the cost of remove stepping over every element. And then you just change it's state, so you avoid the cost of copying over the entire list when something is deleted. At the end you would need to convert back to numbers instead of true/false, but that can be done in 1 pass instead of 100k basses of deleting things.\n\nThe topic that this general idea of thinking about how datais stored and manipulated and algorithms surrounding them is called \"data stuctures and algorithms.\" It's not the most critical thing to learn while you are just becoming familiar with expressing ideas in python, but it is important towards ensuring that programs like what projuct euler challenges you to do run quickly.\n\nHere is a reasonable and interactive book about data structures/algoriths that uses python as its teaching tool.\n\n# [https://runestone.academy/ns/books/published/pythonds/index.html](https://runestone.academy/ns/books/published/pythonds/index.html)",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "pontz",
                            "body": "I can't help any more than you already have gotten but I have to disagree with your choice to not move to a proper IDE.  You are unnecessarily handicapping yourself by not using the tools available within an IDE.  Especially the use of debugger extension in vscode or equivalent function in pycharm.  You would have been able to figure out pretty easily where you were sinking the most time in the program and the skill to debug properly will get you pretty far. You also could use pdb if you're set on not using a comprehensive IDE",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Adrewmc",
            "body": "If I remember right something like the below \n\n       def sieve_of_E(num : int) -> list[int]:\n             sieve = [True] * (num+1) \n\n             #zero and one are not prime by definition\n             sieve[0], sieve[1] = False, False\n\n             #only check to the sqtr()+ 1 because math \n             for i in range(2, (int(sqrt(num)) +1)):\n                   if sieve[i]: \n                        for multiple in range(i*2, num+1, i):\n                            sieve[multiple] = False\n\n             return [num for num, is_prime in enumerate(sieve) if is_prime]\n\nNote: the math is simple, one you\u2019ve gotten to its square root (i have to check that one so +1 to avoid it being excluded in range()) , then the next one that is prime, will already have their multiples of 2, factored out because we should have already done that, and 3, and 5, and 7\u2026up until you get to that higher prime times itself (it squared) which is obviously higher then the upper max, because it is a smaller number squared, n^2 < (n+c)^2  while n,c >= 1  thus all non-primes to that max will have already been excluded.\n                 \n\nYou should also know that itertools provides this [recipe way at the bottom](https://docs.python.org/3/library/itertools.html) for you as well, some of those are clutch. \n\nWhich is much more complex as you can see, as it\u2019s using a byte array to further optimize the process. \n\n    def sieve(n):\n        \u201cPrimes less than n.\u201d\n        # sieve(30) \u2192 2 3 5 7 11 13 17 19 23 29\n        if n > 2:\n            yield 2\n        data = bytearray((0, 1)) * (n // 2)\n        for p in iter_index(data, 1, start=3, stop=isqrt(n) + 1):\n            data[p*p : n : p+p] = bytes(len(range(p*p, n, p+p)))\n        yield from iter_index(data, 1, start=3)",
            "score": 1,
            "replies": [
                {
                    "author": "commy2",
                    "body": "> we only need to check half the number because math \n\n> for i in range(2, num//2):\n\nIt's enough if you do it up to sqrt of num, which without importing anything is:\n\n> for i in range(int(num ** .5) + 1):",
                    "score": 2,
                    "replies": [
                        {
                            "author": "Adrewmc",
                            "body": "It\u2019s been a while okay I\u2019m on my phone here. Also sqrt is intensive isn\u2019t it? It may be easier/faster to forget the calculation i forget.\n\nAnyway, either way, it should be fairly fast.",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "commy2",
                                    "body": "> Also sqrt is intensive isn\u2019t it?\n\nSure, but any loop in C will be much faster than a loop in Py.  2kk takes 1.3s with num//2 and 854 ms with sqrt(num) on my laptop.",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "author": "Adrewmc",
                                            "body": "Well, i guess i missed that, I\u2019ll edit. I guess also with significantly large numbers the iterations would be much less as well.",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "schoolmonky",
                                    "body": "`**` with at least one float input defers to C's `pow` function which is O(1) by virtue of being a float computation (since floats have a fixed size). If the imprecision of floats is a problem, the next best thing would probably be `math.isqrt()`, which has a complexity of [O(log(n)^(2)) at worst](https://stackoverflow.com/a/78076732), still making it far better than `//2`.",
                                    "score": 2,
                                    "replies": [
                                        {
                                            "author": "Adrewmc",
                                            "body": "I have found myself to be in error here, beyond that, at significantly large numbers you just run so many less iterations, that even if // was faster to calculate by magnitudes it would still be faster to to find the sqrt()\u2026i also sort of forgot my math here a little, i knew it was less then half because that\u2019s easy to see, and number above half next multiple would be above my limit, thus I\u2019ve found all of the next half\u2019s factors (if possible)",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "gerenate",
            "body": "Take a look at this\n\nhttps://wiki.python.org/moin/TimeComplexity",
            "score": 1,
            "replies": []
        },
        {
            "author": "Xappz1",
            "body": "You don't need to keep track of lists of numbers. Spawn a list of N (2mil) boolean values (seeded with True) with `is_prime = [True] * N` and use the list index to your advantage: `is_prime[i]` should code if the integer i is a prime or not.\n\nYou can then manually set `is_prime[0] = is_prime[1] = False` as those aren't prime numbers, and start your loop from 2 to sqrt(N). At each step i, if `is_prime[i] == True` then you are absolutely sure it's a prime without having to check any math, and then you proceed to mark all its multiples from i*i to N as False. Loop until you find the next True, rinse and repeat.\n\nAt the end you just need to sum all primes with something like `sum(i for i, p in enumerate(is_prime) if p)`",
            "score": 1,
            "replies": []
        }
    ]
}