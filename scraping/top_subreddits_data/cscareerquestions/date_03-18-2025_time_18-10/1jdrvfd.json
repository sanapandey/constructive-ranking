{
    "title": "AI is not there yet to replace SWEs. Either my prompts are shit or AI isn't at that state to replace Software Engineers.",
    "author": "No_Pollution_535",
    "subreddit": "cscareerquestions",
    "rank": 10,
    "score": 199,
    "upvote_ratio": 0.88,
    "num_comments (reported by reddit)": 148,
    "url": "https://www.reddit.com/r/cscareerquestions/comments/1jdrvfd/ai_is_not_there_yet_to_replace_swes_either_my/",
    "id": "1jdrvfd",
    "selftext": "Using Sonnet 3.5 model to migrate clients to use our team's platform by adding needed configuration changes  and it can't never be consistent even with the easiest changes. \n\nPrompts are detailed enough and down to step by step that a human should be able to follow but AI still can't make the changes correctly. \n\nEither my prompts are shit or AI isn't at that state to replace Software Engineers.",
    "comments": [
        {
            "author": "fake-bird-123",
            "body": "I'm using sonnet 3.7 and agree. OpenAI doesn't have anything on the level of 3.7 for coding just yet. We're at the point of diminishing returns. The LLMs are like a forgetful Jr dev with a concussion in their current state.",
            "score": 189,
            "replies": [
                {
                    "author": "zeros-and-1s",
                    "body": "> forgetful Jr dev with a concussion\n\nlol this is a great way of describing their current functionality.",
                    "score": 53,
                    "replies": []
                },
                {
                    "author": "Fidodo",
                    "body": "Same. I've been using sonnet 3.7 for prototyping and while it's great for rapidly testing out ideas, the code it produces is trash I'd never commit. Outdated practices, security flaws, not using standard libraries efficiently, module interfaces with too much surface area, etc.\n\n\nThe coding style is out of date and like it was pulled from a tutorial written naively to illustrate the code in an extra simplistic way because that's where the training data came from.\n\n\nThe LLMs are plateauing and not improving at the same rate as before so to get around that AI companies are creating these thinking models which are more akin to optimized prompt engineering workflow loops than anything foundational, and they won't be able to prompt engineer their way out of this problem because the core of the probability model simply can't find the info space to produce a better quality answer. I've tried to directly tell it to change specific things about the code and it fails to contextualize the changes and repeats the same mistakes over and over again. I've tried some experiments to see if I could get it to produce code up to my code review standards by giving it feedback and it either fails even with direct instruction or takes forever to get to the right solution.\u00a0\n\n\nFor example, I was trying out V0 to create a relatively simple app, and it had a state bug that was preventing an interaction from triggering and I was telling it the exact place it was happening and how to fix it and it took like 5 tries to get it to actually fix it and it was a simple bug too. Similar things have happened when using sonnet 3.7.\n\n\nPeople are so dumb to believe the AI company marketing bullshit. \"It's going to be a better programmer than humans in a year\" *at tightly sandboxed competitive coding challenges that have direct examples the LLM has been trained on.",
                    "score": 27,
                    "replies": [
                        {
                            "author": "mgalexray",
                            "body": "Fully agree. I don\u2019t use LLMs that much but I had the same experience - sonnet 3.7 seems to spit out mountains of code without much thought or structure to it. I always end up just asking the o1 the same questions and produces what I would judge a much higher quality result.",
                            "score": 6,
                            "replies": []
                        },
                        {
                            "author": "TopNo6605",
                            "body": "They're trained on the most available data and that data is usually outdated docs and blog posts. Code that works but isn't really new.",
                            "score": 3,
                            "replies": [
                                {
                                    "author": "Fidodo",
                                    "body": "Exactly, and it's normally example code from tutorials which are not production ready since they cut a lot of corners to illustrate the core concept more clearly. A programmer knows how to apply them into their codebase, LLMs basically just repeat the tutorial code with minor transforms.",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "blackashi",
                            "body": "I agree with you but you're missing the point. \n\nFor this sub, ai only helps not enables new tech and ideas, but for the non-sw engineers, it enables them to try things they otherwise would have 0 knowledge or inclination to do.",
                            "score": -4,
                            "replies": [
                                {
                                    "author": "Fidodo",
                                    "body": "The topic of this post is whether or not LLMs can replace SWEs. It needs to produce production quality code to do that. It's great at prototyping and letting non coders prototype, but this discussion is about whether LLMs will be able to code as well as a professional.",
                                    "score": 16,
                                    "replies": [
                                        {
                                            "author": "strongerstark",
                                            "body": "Even my non-coder partner was frustrated by the number of times they got led down a rabbit hole while trying to complete a simple task.",
                                            "score": 4,
                                            "replies": [
                                                {
                                                    "author": "Fidodo",
                                                    "body": "If it's anything like my experience then it's not even the correct rabbit hole. I have the experience to know when it's gotten into a bad space that won't solve the problem, but for non coders you'd be having it incorrectly explore a solution without knowing it was wasting your time. I have a hard time getting it to focus on finding a correct solution as a professional, it must be horribly frustrating to try to work with it when you don't know what it should be doing.",
                                                    "score": 3,
                                                    "replies": [
                                                        {
                                                            "author": "Professor_Goddess",
                                                            "body": "Yeaaahhh I come and go on it. I do find it really useful, but moreso in a \"suggest some code for this and then I'll make it work\" tool. It's great at *teaching* coding too. I like it a lot better for that than for actually coding for me. I'm learning programming while also using AI frequently, and it's helped me a ton, but I've also had to develop a sense of when I need to tell it \"hold up, that's stupid.\" And then it will go \"yeah hmm true\" and change course. Kind of funny tbh.",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "ImportantDoubt6434",
                    "body": "The dev also is hallucinogenic and imports modules that don\u2019t exists\u2026",
                    "score": 10,
                    "replies": []
                },
                {
                    "author": "kfelovi",
                    "body": "3.7 is too verbose and overly confident",
                    "score": 15,
                    "replies": [
                        {
                            "author": "fake-bird-123",
                            "body": "You could sub in any LLM for that and it wouldn't change the rest of the sentence.",
                            "score": 18,
                            "replies": []
                        },
                        {
                            "author": "Fidodo",
                            "body": "And bad at implementing feedback",
                            "score": 3,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "zobee",
                    "body": "A Jr dev with great comm, googling, and synthesizing skills, but in terms of looking at the big picture a junior dev nonetheless. Like a Lit PhD turned coder.",
                    "score": 5,
                    "replies": []
                },
                {
                    "author": "tjdavids",
                    "body": "3.5 is better than 3.7, 3.7 thinking or 3.7 max. But if you want an example for the poc and you are a product owner it doesn't have to be good because your other choice is to explain what your product is not explain hown it is different from the example.",
                    "score": 4,
                    "replies": [
                        {
                            "author": "Fidodo",
                            "body": "I use it for rapid prototyping and it's great for that because I'm going to throw out the code anyways and I can test out ideas quickly. It's just not great if you want to produce code you should actually use.",
                            "score": 3,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "No-Issue-9136",
                    "body": "Do you have o1 pro? O1 pro is better than 3.7.",
                    "score": 1,
                    "replies": [
                        {
                            "author": "fake-bird-123",
                            "body": "Not at coding. I had access to O1 pro for two months and it's an amazing model, but it simply isn't on the same level for coding. This seems to be a recurring theme with OpenAI. I won't sit here and act like I'm on the same level as their research teams, but they need to close the gap if they want to justify that $200/month price point.",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "No-Issue-9136",
                                    "body": "I pay for it and it's worth it when it works but they will nerf you at their leisure which really pisses me off. I also got too reliant on it. It did entire projects for me and I looked like a jack ass because I couldn't explain them. So I learned to just use it for a single function refactor at most",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "None",
                    "body": "[deleted]",
                    "score": 0,
                    "replies": [
                        {
                            "author": "fake-bird-123",
                            "body": "Not even remotely true. I've been using Cline for months now. That's why these tools are even passable right now. If they're game changers for you... well, maybe we should have LLMs replace a few of our lower performing colleagues like yourself.",
                            "score": 0,
                            "replies": [
                                {
                                    "author": "denkleberry",
                                    "body": "Yeah go for it. Replace your juniors with LLMs \ud83d\ude02. I was responding to your point about it forgetting. You're not using it to its full potential. I'm the lead engineer at my company and I basically dual code with Cline on one branch and myself on another. You need to micromanage it with constraints and rules, but it still saves a fuckton of time. And outperforms any junior, as long as you put in the work to learn it. I should probably just delete my posts tbh. By this time next year, y'all will be pair programming with AI though.",
                                    "score": -2,
                                    "replies": [
                                        {
                                            "author": "fake-bird-123",
                                            "body": "I'm not talking about my juniors. I've hired actual engineers. Based on what you've said in this thread, I'd trust their work over yours by quite a large margin and the one only graduated a year ago.",
                                            "score": 3,
                                            "replies": [
                                                {
                                                    "author": "denkleberry",
                                                    "body": "Yeah I was kidding. It absolutely suck. Not worth looking into.",
                                                    "score": 0,
                                                    "replies": []
                                                }
                                            ]
                                        },
                                        {
                                            "author": "strongerstark",
                                            "body": "Then you're bad at communicating with humans. With good communication, juniors can be incredibly efficient and don't require micromanaging.",
                                            "score": 1,
                                            "replies": [
                                                {
                                                    "author": "denkleberry",
                                                    "body": "Look I'm not advocating for replacing juniors with LLMs here because that would be stupid but a junior isn't going to build a complete project using hexagonal architecture with perfect variable names, decent tests, and docker deployable in 8 hours.",
                                                    "score": 0,
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Synclicity",
                    "body": "I'm using sonnet 3.7 as well with a large context window, and it's directly replaced the need for me to hire extra devs. Even if it can't directly replace a dev, if a dev uses it to improve their efficiency it'll still make a whole lot of dev jobs obsolete by efficiency increase. \n\nFurthermore, it solves the problem of \"too many cooks in the kitchen\". There are times I need to bash out a whole lot of code while knowing I can't hire devs to help me because it'll require too much training/guiding or it's a one-off specialized task. Being able to generate ~1000 lines of code per prompt with what I want, and just changing a few lines to fix claude's mistakes is worth way more than an extra couple of junior devs.\n\nIt's opened up a new world of possibilities with what has been formerly impossible just by throwing extra devs at the problem. Also, I'm writing pretty cutting edge stuff and claude still knows how to interpret my prompts.\n\nEDIT: Lol OP blocked me so I can't reply to any post in this chain now. Funny behaviour. Called me out for being an undergrad when I have posts talking about my work in this subreddit from 2016.",
                    "score": -10,
                    "replies": [
                        {
                            "author": "fake-bird-123",
                            "body": "Whatever you're doing must not be very complex if 3.7 is doing all of that for you.",
                            "score": 13,
                            "replies": [
                                {
                                    "author": "Synclicity",
                                    "body": "There are very few problems in computer science that can't be broken down into simple steps. If you know how to code it you would know how to prompt it.",
                                    "score": -10,
                                    "replies": [
                                        {
                                            "author": "fake-bird-123",
                                            "body": "I've been working in this field for over a decade. I am very aware of how to break down big problems into small problems. Again, if sonnet is doing all of that for you, what you're doing simply isn't that complex.",
                                            "score": 11,
                                            "replies": [
                                                {
                                                    "author": "Synclicity",
                                                    "body": "Agree to disagree tbh, because I've also been a professional for 7 years and coding for a decade. The effectiveness of LLMs for coding is probably domain dependent, and for my usecases it's done wonders. And I would consider it sufficient for 99% of corporate coding jobs considering they don't do anything special. My friends that are tech cofounders for YC use LLMs heavily as well and consider it a pair programmer for all the dev work they do. The important thing to note is it isn't meant to be able to invent any code you can't write yourself, that isn't its function.",
                                                    "score": -8,
                                                    "replies": [
                                                        {
                                                            "author": "fake-bird-123",
                                                            "body": "> And I would consider it sufficient for 99% of corporate coding jobs considering they don't do anything special.\n\nLMFAO What kind of stupid as fuck take is this? If this is truly your take then you've never worked a day in this field.",
                                                            "score": 10,
                                                            "replies": [
                                                                {
                                                                    "author": "Synclicity",
                                                                    "body": "You're right, I haven't worked a day in this field and everything I said was made up. Noone on this subreddit has been coping about the job market since LLMs became popular because the jobs for devs are all still there.",
                                                                    "score": 0,
                                                                    "replies": [
                                                                        {
                                                                            "author": "fake-bird-123",
                                                                            "body": "You're definitely still in undergrad with this string of takes. How about leaving the discussion about workplace tools to those of us actually in the workplace?",
                                                                            "score": 7,
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "author": "PedroAmarante",
                                                            "body": "What have you been coding?\nI work in embedded/ Linux kernel and it is bad",
                                                            "score": 4,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "babypho",
            "body": "You don't have to convince us. You have to convince the board people or execs who don't know how to code. All they see is that they can replace 5 engineers for 1 engineer with chatGPT. \n\nIf money numbers go up, even in the short run, that's a win. \n\nIf numbers go down, it's WFH and lazy engineers' fault.",
            "score": 85,
            "replies": [
                {
                    "author": "Fidodo",
                    "body": "And all the people who fall for marketing bullshit. Their claims are ridiculously cherry picked marketing bullshit like saying it will be better than human programmers in a year but when you look at what they're basing it on, they're using competitive coding challenges as the baseline. Yeah no fucking duh it's going to be better at programming problems that are a sight variation of a problem it already has the answer to in its training data. I'd be really great at competitive coding too if I could reference a dozen similar examples to base my answer off of during a competition.",
                    "score": 14,
                    "replies": []
                }
            ]
        },
        {
            "author": "loudrogue",
            "body": "Yes the companies are grifting. Remember how self driving has only been a few years away? For literally a decade+ now and we are still no where close",
            "score": 205,
            "replies": [
                {
                    "author": "West-Code4642",
                    "body": "Waymo (and others) are very close. Tesla is far away cuz of lack of lidar\u00a0",
                    "score": 49,
                    "replies": [
                        {
                            "author": "abrandis",
                            "body": "Waymo is not close , sure in a few very local markets where they napped the shit out of the roads , go try to take a waymo from. Phoenix to an outside suburb that's more than a 30min ride..  plus even with that Waymo needs a massive human. Monitoring center and field techs , that's why waymo has been a big money loser since it started .\n\nThe reality is there's still lots of holes in the self driving tech , to see what funny chaos ensues..when self driving gets into gridlock\n\nhttps://youtube.com/shorts/E7ulhOcFfI0?si=EqyFQJQLXxLcuCGS",
                            "score": 24,
                            "replies": [
                                {
                                    "author": "Lycid",
                                    "body": "I live in SF bay area, Waymo is pretty much there. I prefer them to Uber because they drive more consistently smooth. The only case where it fails is trying to pick up people after a big concert or music festival goes out due to the non stop crowds of people but that's a situation even an Uber would struggle in. It otherwise makes accurate and good decisions navigating even odd situations like driving around cars making illegal turns in complicated intersections infront of them or just being able to navigate around traffic in general.\n\nThe thing that makes Waymo work is it's essentially acting like a form of public transit (no freeways, limited to only the city they operate in) and it's just filled to the brim of crazy good sensors and sensor data. It has enough to work on to handle 99% of what you throw at it.\n\nJust because you can't take a Waymo from SF to Tahoe does not mean that it is \"not close\", that is an unreasonable expectation and missing the use case of the tech. it's like saying EVs are \"not close\" to being a mature tech because you aren't able to drive 1000 miles on a single charge or because they aren't being used in shipping yet.",
                                    "score": 3,
                                    "replies": [
                                        {
                                            "author": "abrandis",
                                            "body": "You know what else works great just in the city....mass transit....  Your arguments  reminds me of this Silicon valley sketch..\nhttps://youtu.be/9YOEEpWAXgU?si=7nBYzZc1Ck_eV09q",
                                            "score": 3,
                                            "replies": [
                                                {
                                                    "author": "Lycid",
                                                    "body": "You're being facetious. Public transit is good and SF has pretty good public transit. So does London, so does Tokyo. Guess what? All of these cities have cabs too and still have a need for some \"pick up anywhere\" capability. It turns out public transit isn't a magical solution to every journey's needs even in incredibly walkable cities. My comment comparing it to transit was simply making the observation that the service is hyper localized like public transit and isn't designed to do things like take you to the next town/suburb over or even the airport like a cab would.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "author": "abrandis",
                                                            "body": "But that's kinda of an issue most people dont use Uber if mass transit is available and more convenient, Uber and other taxi like services are for intracity , that's where they're most beneficial",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Adept_Carpet",
                                    "body": "You can't have full self driving cars without AGI.\n\n\n\nAt least a few times a year I encounter something like a cop at an accident site who shouts or gestures instructions that you need to follow immediately, a hastily setup detour with text instructions on a sign, or the need to make unusual maneuvers due to snow/ice/puddles/etc.\n\n\nWhat would a self driving car without AGI or a licensed driver inside do? Just stop and wait for a tow truck?",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "SanityInAnarchy",
                                            "body": "I don't think you need AGI to get close enough for it to be useful. I mean, depending how you count, we already have pretty good lane-keeping and adaptive cruise control.\n\nBut the goal people talk about is something like: Keep the monitoring center and keep the field techs, keep the ability to take over and drive a car remotely, but you still come out ahead if most cars won't need human supervision most of the time. (To be clear, Waymo isn't there yet.)\n\nIf these things get popular enough, there could be standardized ways for authorities to redirect traffic like this if needed. I've never run into something like this where there aren't at least cones out trying to direct traffic, but maybe there could be an electronic system, too. And, meanwhile, if the project *really* succeeded, maybe you have fewer accidents in the first place.\n\nI think there are two huge problems with this, and they aren't really technological.\n\nProblem #1: If you really want to reduce the number of humans who need to control the machines driving us around, we already have a better, simpler technology for that: Trains.\n\nProblem #2: Humans aren't *that* expensive. There are plenty of *much easier* problems that we've come up with automation for, and then abandoned because it was cheaper to just pay a human to do it.",
                                            "score": 2,
                                            "replies": [
                                                {
                                                    "author": "emelrad12",
                                                    "body": "Idk man humans are crazy expensive, for example to staff a single position 24/7, you would need around 3 humans, but considering the average working hours per person per year are at 1600-2000 as people dont work 365 days a year, that means you would need up to 6 humans.\n\nIf each costs 50k salary, then with benefits and all that comes to around 60-70k.\n\nIn total that means up to 420k per year to staff a single spot 24/7.\n\nOverall humans are cheaper argument only work when the technology is very very immature.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "author": "strongerstark",
                                                            "body": "How much do you think it costs to train (never mind research) a single LLM?",
                                                            "score": 1,
                                                            "replies": [
                                                                {
                                                                    "author": "emelrad12",
                                                                    "body": "What is your point? That is like saying in 1900s that a horse is cheper and faster than a car. That might be true for now, but wont be true after few decades.",
                                                                    "score": 1,
                                                                    "replies": [
                                                                        {
                                                                            "author": "SanityInAnarchy",
                                                                            "body": "Maybe. Or maybe it's like in the 1900s saying that [those \"land ironclads\" will never actually be that big](https://en.wikipedia.org/wiki/The_Land_Ironclads), or that [airships won't be used to carry mail](https://en.wikipedia.org/wiki/With_the_Night_Mail).\n\nOr maybe like, in the 60's, saying we won't have [flying cars](https://en.wikipedia.org/wiki/The_Jetsons). Or we will, but they'll generally be worse than airplanes at being airplanes, and worse at cars than being cars.",
                                                                            "score": 1,
                                                                            "replies": []
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        },
                                                        {
                                                            "author": "SanityInAnarchy",
                                                            "body": "First: Who says each gets 50k in salary? Federal minimum wage comes to more like $15k. And since we're talking about a taxi service, ridesharing can go even below that, because they aren't technically employees, and because they generally aren't paid unless they're actively moving someone. There's a more dystopian effect here: The more people are put out of work by automation, the cheaper labor gets, because market forces apply to human resources, too.\n\nSecond: Who says we need the same capacity 24/7? Again, we're talking about a taxi service -- maybe you need *someone* to be able to respond at 3 AM, but you'll need far more people from 8 to 10 AM. After all, your customers are human, too. [Here's the relevant xkcd.](https://xkcd.com/1205/)\n\nThird: Automation carries its own costs. There's the enormous up-front cost to develop the tech in the first place -- anything you think is \"very very immature\", how do you think it ever gets past that? -- but then there's ongoing debugging and support. [Here's a relevant XKCD for that one.](https://xkcd.com/1319/) Funny thing about both of these XKCDs is they're about *software* -- the kind of automation they're talking about doesn't even have any physical robotics to solve -- yet it's still not always worth it.\n\nRobots are also generally less flexible than humans. Does it make sense to have a robot burger-flipping machine in a fast food restaurant? We definitely have the technology to do that -- in fact, we have entire assembly lines that can build and package some pretty complicated things, including foodstuffs. It should take far less intelligence to do that than it does to drive a car. So why don't you see it in fast-food restaurants? Well, you can't *just* replace the burger-flipping machine, you'd also have to fully-automate *all* of the food-prep stuff -- not just the burgers, but the fries, the assembly, and so on -- and also cleaning the kitchen, cleaning the dining room and restroom if you aren't *just* a drive-thru, unpacking new food, detecting and throwing away spoiled food, and so on and so on. Humans can move between those jobs depending on demand -- if you've dropped to one customer every half-hour, then even your burger-flipper could go clean stuff.\n\nObviously, sometimes automation does make sense and takes over. But competing with the price of human labor is a challenge, and it's one that not all attempts at automation ever clear.",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "CacheMeUp",
                                    "body": "Humans also don't really know how to drive without the appropriate infrastructure, e.g. not all humans can handle offroad driving. \n\nAutonomous driving will work in specific environments, and those environments will reap exponential economic rewards. My first-hand impression is that even Tesla's limited approach could work if human drivers were removed and the roads were marked accurately.\n\nThere are places where horses can go that cars cannot. That did not make cars moot. It made those places economically die.",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "dietcokeeee",
                            "body": "Self driving will never work 100% unless all cars on the road are autonomous. There are too many things you can\u2019t predict if humans are driving.",
                            "score": 43,
                            "replies": [
                                {
                                    "author": "icefrogs1",
                                    "body": "I agree, but have you seen humans drive? They give driver's licenses away in the US.",
                                    "score": 16,
                                    "replies": [
                                        {
                                            "author": "ForsookComparison",
                                            "body": "I think I drive significantly better than Tesla FSD.\n\nBut.\n\nI think Tesla FSD (on HW4 models) drives better than at least half of the people I share the road with and would feel far more safe with a bunch of Teslas+Waymos+Whatever's than those people",
                                            "score": 4,
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "usernamesrhardmeh",
                                    "body": "They don't have to work 100%, they have to work better than humans",
                                    "score": 42,
                                    "replies": [
                                        {
                                            "author": "Dasseem",
                                            "body": "And that's why they need to be perfect. It's as simple as that.",
                                            "score": -22,
                                            "replies": [
                                                {
                                                    "author": "KrispyCuckak",
                                                    "body": "Because human drivers are perfect?",
                                                    "score": 9,
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "West-Code4642",
                                    "body": "Waymos cars seem to work well",
                                    "score": 21,
                                    "replies": [
                                        {
                                            "author": "KetoSaiba",
                                            "body": "Former waymo worker. No they aren't. They get pulled off the road for weather beyond a light rain.\nThey're really bad at updating for changes in construction (traffic cones, signs). \nSo they work, in currently only 2 cities, within very narrow parameters, with someone having to observe each car 24/7.",
                                            "score": 47,
                                            "replies": [
                                                {
                                                    "author": "One_Tie900",
                                                    "body": "who needs Waymo when you have Blue Eyes White Dragon",
                                                    "score": 12,
                                                    "replies": [
                                                        {
                                                            "author": "beefycabbageavenger",
                                                            "body": "Something tells me he has the White Eyes Blue Dragon",
                                                            "score": 5,
                                                            "replies": []
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "GeneralPeanut",
                                                    "body": "Isn\u2019t it in four cities right now? Phoenix Austin San Fran and LA",
                                                    "score": 1,
                                                    "replies": []
                                                }
                                            ]
                                        },
                                        {
                                            "author": "ares623",
                                            "body": "IIRC they have a pool of remote drivers on standby ready to take over whenever needed.",
                                            "score": 0,
                                            "replies": [
                                                {
                                                    "author": "Candid_Hair_5388",
                                                    "body": "Rider support is not that active. I got stuck once when a guy directing traffic didn't want to give hand signals to the Wyamo (maybe a previous Waymo already failed and he was frustrated). I called rider support. We got going and finished our trip long before we got connected. I don't think they're observing the trip that closely.",
                                                    "score": 2,
                                                    "replies": []
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "apotheotical",
                                    "body": "Unless all cars are autonomous AND people don't go outside.",
                                    "score": 2,
                                    "replies": []
                                }
                            ]
                        },
                        {
                            "author": "NWOriginal00",
                            "body": "Level 5 still seems a long way off, despite millions of hours of training data. When we have an AI that can learn to drive in 20 hours like a teenager, then our profession is probably done.  I have no idea if that happens next year, or decades from now.",
                            "score": 2,
                            "replies": [
                                {
                                    "author": "maikuxblade",
                                    "body": "Likely decades. LLM tech is going to top out, it\u2019s ultimately just a really clever series of linear regressions and it\u2019s never going to become AGI.",
                                    "score": 14,
                                    "replies": [
                                        {
                                            "author": "kfelovi",
                                            "body": "They already spend 1000% more resources to make 20% smarter model",
                                            "score": 11,
                                            "replies": []
                                        },
                                        {
                                            "author": "Ready_Big606",
                                            "body": "It largely already has. ChatGPT 4.5 is if anything worse at coding than 4.0 and reviews of Claude 3.7 are....mixed is probably the most generous way to put that. While figures aren't public ChatGPT 4.5 took multiple training runs of at least a few hundred million dollars per run and that was the best they got. Not to mention how much more expensive inference is with the model.",
                                            "score": 6,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "NanoYohaneTSU",
                            "body": "No they aren't. You are being tech scammed. If the tech was there we would have already had it by now. It's been more than enough time.",
                            "score": 1,
                            "replies": []
                        },
                        {
                            "author": "lord_heskey",
                            "body": "> lidar\n\nOr leader..",
                            "score": 0,
                            "replies": [
                                {
                                    "author": "emelrad12",
                                    "body": "what?",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "lord_heskey",
                                            "body": "Tesla is far away bc of lack of leadership (Elon)..",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "qadrazit",
                            "body": "Tesla already did it if we trust their statistics, their fsd 13 is 10 times safer in terms of accident frequency than average human driver. Not sure why would they need a lidar to be honest, it looks like a crutch to me from the logical point of view",
                            "score": -12,
                            "replies": [
                                {
                                    "author": "mewditto",
                                    "body": "> their fsd 13 is 10 times safer in terms of accident frequency than average human driver\n\nIsn't this because the FSD turns off the moment it sees an unfamiliar situation, so technically it's 'off' during the accident it couldn't handle?",
                                    "score": 10,
                                    "replies": [
                                        {
                                            "author": "Ganluan",
                                            "body": "No, they include any accidents where it was active in the previous 10 seconds",
                                            "score": 3,
                                            "replies": []
                                        },
                                        {
                                            "author": "qadrazit",
                                            "body": "I have no idea how they gather statistics and whether they incorporate into it what you said. its just what they report. You could be right, you could be wrong idk. Based on what ive seen driving around in those, they perform extremely well and are very safe.",
                                            "score": 2,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "RickyNixon",
                    "body": "I took 4 Waymos today, theyre here dude\n\nAs for Gen AI - it\u2019s not useless for dev tasks. I use mine to spin up large amounts of test data, sometimes I ask it about unclear error messages, sometimes if I\u2019m expected to understand a tool in a programming language I\u2019m not familiar with I\u2019ll ask it questions about snippets \n\nI\u2019m not replacing a dev with it, but I get a lot of use out of it. It doesnt live up to the hype, but its not worthless either",
                    "score": 13,
                    "replies": [
                        {
                            "author": "NotFlameRetardant",
                            "body": "Yeah, your use cases are pretty similar to mine. I just switched over to the consultancy realm a few months ago and Gen AI has been pretty handy at ingesting, debugging, and documenting undocumented codebases we inherit in languages I don't typically use that haven't been updated in a decade.",
                            "score": 5,
                            "replies": []
                        },
                        {
                            "author": "loudrogue",
                            "body": "Can I drop a waymo in a completely random area in the USA and it successfully drive back to SF? Because if it requires years of test driving in the area then it's not really here.",
                            "score": 6,
                            "replies": [
                                {
                                    "author": "RickyNixon",
                                    "body": "I\u2019m in Austin, I saw the first one Ive ever seen less than 6 months ago. Its been a few weeks since Uber started suggesting them to me, and today I took 4 (I had to uber to/from two medical appointments)\n\nPicked me up and dropped me off in a complicated downtown area, it was pretty good dude. I was scared the first time, but by the end I was earnestly impressed and changed my settings to keep getting them. There was this left turn with a blinking yellow and a bunch of people doing erratic things that was making me nervous, but it nailed it.\n\nI\u2019m sure theres limitations, I\u2019m in the middle of the city, but yeah it was impressive. Better than I expected by a lot.",
                                    "score": 5,
                                    "replies": [
                                        {
                                            "author": "bautin",
                                            "body": "The first one *you* saw. That's not to say they weren't plotting Austin like they were before. They currently operate in four cities and are planning on two more.\n\nNew York, Boston, Chicago, Philadelphia, Detroit, Seattle, Houston, and Dallas are all not on that list.\n\nWaymo is probably the best of the lot, but it seems to require a bunch of upfront work to make it work like it does. But credit to them, they aren't shying away from admitting that and doing the work.",
                                            "score": 1,
                                            "replies": [
                                                {
                                                    "author": "RickyNixon",
                                                    "body": "The announcement that they WOULD be coming was almost exactly a year ago. So, maybe they were here for 2-3 months before I saw one. Less than a year aint bad\n\nhttps://x.com/saswat101/status/1765119905811288493",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "author": "bautin",
                                                            "body": "They also said that this was after months of careful testing. Which comes later in the process.\n\nLike, I don't mind if they take a year or two to plan, implement, and test things if the result is that it works.\n\nBut Waymo clearly isn't a \"drop and go\" kind of system. And they're not even claiming they are. You are doing that.",
                                                            "score": 0,
                                                            "replies": [
                                                                {
                                                                    "author": "RickyNixon",
                                                                    "body": "Where did I claim that? This line of argument began, for me, with someone saying training takes impractically long and means self driving cars are \u201cnot really here\u201d. I\u2019m rebutting that assertion.",
                                                                    "score": 1,
                                                                    "replies": [
                                                                        {
                                                                            "author": "bautin",
                                                                            "body": "No, he said that you couldn't drop a Waymo anywhere and have it drive to San Francisco [link](https://www.reddit.com/r/cscareerquestions/comments/1jdrvfd/ai_is_not_there_yet_to_replace_swes_either_my/midgqd7/).\n\nYou then countered with the first time you saw it in Austin and that it worked fine for you. With the implication that the difference between the time it took for you to see it and the time you were able to order it means that's how long they took to get it set up for Austin. [link](https://www.reddit.com/r/cscareerquestions/comments/1jdrvfd/ai_is_not_there_yet_to_replace_swes_either_my/midhrbe/)\n\nI mentioned that you may not have seen all the other stuff they did before you saw the first car.\n\nYou then said they announced they'd be coming a year ago.\n\nI pointed out that even in that tweet, they admit that there's been months of testing prior to making that announcement. And that testing is the last stop so months of testing comes after months of other things as well. I also mentioned that it's very responsible of them.\n\nSo you've not even addressed the thing you're claiming to be addressing. You said that \"self driving cars are here\", some guy responded with they only work in very narrow situations and can't manage to travel between cities even. He never mentioned training time. You seem to be under the belief that the training time is far less than it is. And no one has said that the time is impractically long.\n\nYour central thesis is that \"self-driving cars are here\". lordrogue defines that as being able to drive from one location to another. You've not addressed that.",
                                                                            "score": 0,
                                                                            "replies": [
                                                                                {
                                                                                    "author": "RickyNixon",
                                                                                    "body": "His conclusion was \u201c\u2026 then [self driving cars] isnt here yet\u201d",
                                                                                    "score": 1,
                                                                                    "replies": [
                                                                                        {
                                                                                            "author": "bautin",
                                                                                            "body": "Yes, because of his condition that he stated. That it can't drive between cities.\n\nIt can't. Nothing you've said addresses that.",
                                                                                            "score": 0,
                                                                                            "replies": [
                                                                                                {
                                                                                                    "author": "RickyNixon",
                                                                                                    "body": "The statement was \u201cif it requires years of testing driving in an area it isnt ready yet\u201d.\n\nClear if/then statement.",
                                                                                                    "score": 1,
                                                                                                    "replies": [
                                                                                                        {
                                                                                                            "author": "bautin",
                                                                                                            "body": "Well, we don't know exactly how much driving it requires.\n\nThey're currently driving around New Orleans and there is no plan to take riders yet.\n\nBut we do know it's at least months. And more than you initially thought.",
                                                                                                            "score": 0,
                                                                                                            "replies": [
                                                                                                                {
                                                                                                                    "author": "RickyNixon",
                                                                                                                    "body": "I\u2019m responding to a clear if/then statement, not making my own case. It sounds like you\u2019re not interested in defending that statement, right?",
                                                                                                                    "score": 1,
                                                                                                                    "replies": []
                                                                                                                }
                                                                                                            ]
                                                                                                        }
                                                                                                    ]
                                                                                                }
                                                                                            ]
                                                                                        }
                                                                                    ]
                                                                                }
                                                                            ]
                                                                        }
                                                                    ]
                                                                }
                                                            ]
                                                        }
                                                    ]
                                                },
                                                {
                                                    "author": "ChrisC1234",
                                                    "body": "They're *supposedly* coming to New Orleans this year... That's gonna be a $#!+show for sure.  New Orleans has traffic signals that aren't always working, lanes unmarked for so long that even the humans don't know how many lanes there are supposed to be, and potholes that can swallow entire cars.  I can't wait to watch the hilarity ensue.",
                                                    "score": 1,
                                                    "replies": [
                                                        {
                                                            "author": "bautin",
                                                            "body": "I checked the website, they just had Miami and Austin in the \"coming soon\" area. Where did you hear New Orleans?\n\nMaybe they're coming to do the initial mapping?\n\nEdit:\n\nI found [this](https://www.axios.com/local/new-orleans/2025/02/06/waymo-driverless-cars-new-orleans) which begins hilariously.\n\n> Waymo will soon send a \"limited fleet\" of its cars to New Orleans so it can continue training its driverless AI on \"varied road features,\"\n\nYes, \"varied road features\" is a way to describe it.\n\nAnd more reading says that this is just essentially training/testing runs. People driving Waymo cars around New Orleans to get the lay of the land and that there are no plans to extend service to the city at the moment.",
                                                            "score": 1,
                                                            "replies": []
                                                        }
                                                    ]
                                                }
                                            ]
                                        }
                                    ]
                                },
                                {
                                    "author": "Lycid",
                                    "body": "No but this analogy is like saying that EVs aren't \"here\" because you can't drop an ev in the middle of Siberia and hope to drive to Paris or the horn of Africa without issue. Just because a Waymo doesn't handle an impossible situation that it isn't designed to replace doesn't mean it isn't here working just fine right now.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "loudrogue",
                                            "body": "So the impossible situation is driving in America that's not a major city that's already using waymo\n\n\nAnd your analogy is literally putting an EV in the middle of absolutely nowhere with no infrastructure",
                                            "score": 0,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "lupercalpainting",
                    "body": "Took a Waymo during SXSW, it was great. Navigated a narrow street with pedestrians and a feeder just fine.",
                    "score": 5,
                    "replies": []
                },
                {
                    "author": "ActiveVegetable7859",
                    "body": "They work fine in SF. They\u2019re all over the place.",
                    "score": 4,
                    "replies": [
                        {
                            "author": "loudrogue",
                            "body": "Right but I would kinda hope so considering they have been actively testing it there since like 2021",
                            "score": 5,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "Droi",
                    "body": "Remember how Devin only solved 13% of SWE-Bench and everyone here made fun of AI, and a year later today the state of the art is 64.6%?\n\nNah, you prefer to only focus on the evidence that you think supports your claim.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "jhkoenig",
            "body": "AI coding is WAY oversold to date. Quick, but really stupid",
            "score": 45,
            "replies": [
                {
                    "author": "floghdraki",
                    "body": "It's like saying \"calculators are going to make mathematicians obsolete!\"\n\nIt's just a really sophisticated algorithm in the end. You can't reduce human existence to just algorithm.",
                    "score": 7,
                    "replies": [
                        {
                            "author": "jhkoenig",
                            "body": "Agreed! AI is just a chatty search engine",
                            "score": 2,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Such-Bus1302",
            "body": "AI is just a productivity tool that helps you do stuff faster. And if you treat it like that it is indeed a very good tool - I think of it as similar to how IDEs or plugins are good productivity tools. Its not an actual drop in replacement for a real developer and should not be used that way.",
            "score": 21,
            "replies": [
                {
                    "author": "justUseAnSvm",
                    "body": "This. Automation never makes jobs go away, it just shifts the distribution of tasks a job is expected to do. My opinion, is that software will soon be \"player coach\" model, where SWEs manage fewer, but way more productive, engineers, and focus on owning outcomes.\n\nWe've already see the \"Engineering Manager\" ranks get absolutely gutted. Organizations are able to take on so much work, and that point of integration will always be the \"tech lead\".",
                    "score": 5,
                    "replies": []
                },
                {
                    "author": "itsmegoddamnit",
                    "body": "Right, so AI doesn\u2019t directly replace an engineer as an entity, but it could allow one engineer to do the job of two engineers.",
                    "score": 2,
                    "replies": []
                },
                {
                    "author": "unprovoked33",
                    "body": "Sadly, this is not the pitch made to your CTO.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "dodiyeztr",
            "body": "If you stay within the limits of their knowledge LLMs will certainly amaze you. Once you hit the walls of their knowledge-spheres then all of the illusion lift and you see them as what they truly are, a bunch of glorified statistical text completion apps.\n\nMost people that has never done anything productive in their lives do not realize the depth of the topics they don't know anything about. Yet they somehow see themselves competent enough to judge the capabilities of an \"AI\". When they see a computer screen spit out the most rudimentary texts they feel amazed because they never truly challenged the limits of the knowledge over the internet.\n\nWhat you experienced is the limits of the knowledge inside that particular model. LLMs can't spit out texts that they have never been trained on. Because they are not intelligent enough to learn from similar topics and then form new knowledge.\n\ntl;dr if they didn't train that particular LLM in the particular topic that you are asking for in your prompt, you won't get an answer. (you won't even get a \"I don't know\" because they don't train for that kind of response either)",
            "score": 30,
            "replies": [
                {
                    "author": "Fidodo",
                    "body": "LLMs can't be trained to say I don't know easily because they don't know when they don't know things. They know that some text is probable to be relevant, but unless it's in a certain sphere of knowledge as you said, it's going to be wrong.\n\n\nYou're spot on. LLMs are basically knowledge retrieval engines, and that's a very powerful thing, but when you're working at a higher level of expertise, you're actually encountering problems that have never been solved before or are extremely obscure all the time. Just last week I had to create a brand new library for a new language where the solution was only described in a singular obscure article and there was only 1 library implementing the solution in a different language than I needed. When I asked an LLM about it while doing research it had zero knowledge of that solution because the information was too obscure for it to come up probabilistically. If I overly relied on LLMs or didn't have the expertise to research other solutions I would have had to deal with a much much more complex implementation.",
                    "score": 6,
                    "replies": []
                },
                {
                    "author": "sb4906",
                    "body": "And here comes some magic stuff called RAG and CAG that can instantly expand the boundaries of the parametric knowledge of LLMs...\n\nIMO SWE job is going to be very different in the next few years, like it or not.",
                    "score": -5,
                    "replies": [
                        {
                            "author": "dodiyeztr",
                            "body": "and here comes the context limit\n\n\"in-context learning\" yeah sure \"learning\". Most of those context sizes are scams anyways. They just internally summarize the text or use other tricks to shorten the tokens that the LLM takes as an input. That is why after like 4k tokens the poor thing starts to disregard the first messages. Let's just say this is a technological limitation that can be overcome over time through the Moore's Law (doubtful with NVDA and the US of A along with the borderline authoritarian EU regulators gatekeeping the f out of it, but whatever)\n\ncan an LLM have a conversation with me, learn something new, and then tell you the next time you are having a conversation with it? It is inherently incapable of doing that. All the \"conversations\" are stateless (it's not even a conversation, just a party trick with special tokens, the backend literally stops generation with an if clause)\n\nI have an MSc. on Artificial Intelligence btw, I'm not defecating these from my back side.",
                            "score": 14,
                            "replies": [
                                {
                                    "author": "cd1995Cargo",
                                    "body": "Thank you for bringing up the point about context sizes. This rarely gets discussed but it\u2019s a big problem even in SOTA models.\n\nThese companies like google and anthropic claiming 100k or one million+ context sizes are so full of shit. I literally watch the quality of the responses take a nose dive after at most 10k context, and that\u2019s being generous. I regularly have to start new chats just to get a somewhat lucid response.\n\nThose \u201cneedle in a haystack\u201d benchmarks they run are meaningless. Turns out being able to pick a single word/phrase out of a novel doesn\u2019t translate to being able to comprehend a large codebase and make nuanced changes to it.",
                                    "score": 8,
                                    "replies": [
                                        {
                                            "author": "Fidodo",
                                            "body": "My company didn't just see a drop in quality, we saw a step function in time to compute as soon as we breached 10k. It was obviously doing some branching logic on a hard cut off\u00a0",
                                            "score": 3,
                                            "replies": []
                                        }
                                    ]
                                },
                                {
                                    "author": "sb4906",
                                    "body": "I said making the job of SWE different, not disappear...",
                                    "score": 1,
                                    "replies": []
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "fsk",
            "body": "The current generation of chatbots can make believable-sounding text.  They just fail for any task that requires precise thinking.\n\nThey can solve toy problems and interview problems, because the answer is in their training set somewhere.\n\nMost of the AIs have an input buffer limit of something like 100k tokens.  If your project is bigger than 100k tokens, it isn't going to work.",
            "score": 6,
            "replies": []
        },
        {
            "author": "vitaminedrop",
            "body": "just started my first ft job at big tech and no lol it\u2019s not gonna replace real devs it literally sucks at writing production code \ud83d\ude2d",
            "score": 10,
            "replies": []
        },
        {
            "author": "Latenighredditor",
            "body": "Unless we fully understand the human brain....which we only know a little about..we won't get to a point where AI will replace SWEs jobs \n\nCreativity and problem solving is hard to put an algorithm into. \n\nCompanies who think they can replace software devs with AI will see the short falls and will start to hire SWEs again. \n\nCertain repetitive tasks maybe automated away but this has been happening long  before this AI wave. Literally like we don't have to type getters and setters when creating new objects it just auto-gen in most popular IDEs. \n\nSo until people who study the brain are fully knowing of most of its functions that can implement into AI, we can probably be safe. \n\nBut it goes to show the everchanging landscape in software engineering.\n\nIf you rely on chatgpt or Gemini or deepseek or co-pilot other AI software to do your work completely for you, you are headed to danger of constantly switching companies if you don't understand the work being done",
            "score": 4,
            "replies": [
                {
                    "author": "emelrad12",
                    "body": "I don't think we need to understand the human brain fully. We are still limited by compute power, for example gpr4 has around 2T parameters, while the brain has 100T. If we assume compute power doubles every 3 years, we will get there in around 20 years.",
                    "score": 0,
                    "replies": []
                }
            ]
        },
        {
            "author": "roksah",
            "body": "AI is a great tool as an excuse for execs to fire people, bring up their numbers and run away before everything burns down",
            "score": 4,
            "replies": []
        },
        {
            "author": "gowithflow192",
            "body": "Let's see the prompts then.",
            "score": 2,
            "replies": []
        },
        {
            "author": "Coreo",
            "body": "They\u2019re just fancy auto completes.",
            "score": 2,
            "replies": []
        },
        {
            "author": "IGotSkills",
            "body": "Yeah bud but watch out for deep seek r2",
            "score": 2,
            "replies": []
        },
        {
            "author": "Mountain-Patient8691",
            "body": "When people say AI is going to eliminate jobs for SWE's in the short term they don't mean the AI will do the entire job. That's later down the line. What they mean is that it will make SWE's much more efficient and productive, which when combined with a set amount of demand for SWE work, will result in lowered need for SWE workers.",
            "score": 2,
            "replies": []
        },
        {
            "author": "Dear_Measurement_406",
            "body": "It can help quite a bit but it can also just as often dig me into a hole.",
            "score": 1,
            "replies": []
        },
        {
            "author": "DirectorBusiness5512",
            "body": "Actually both things are correct",
            "score": 1,
            "replies": []
        },
        {
            "author": "MaverickRavenheart",
            "body": "I kinda laugh at techbros thinking AI will solve anything. If i remember correctly in AI lecture, we as a species cannot differentiate intelligence of our own. How could you proof that you are better than any living things if you cant judge your own self. I think most of these marketing people overhype the AI to do magical things for them and make a profit without an effort to understand what exactly AI is.",
            "score": 1,
            "replies": []
        },
        {
            "author": "BigfootTundra",
            "body": "I agree. I use ChatGPT to save myself some time as a Lead Engineer and it\u2019s an effective tool, but it\u2019s nowhere near ready to replace my day to day job.",
            "score": 1,
            "replies": []
        },
        {
            "author": "Hog_enthusiast",
            "body": "Honestly I use AI whenever it\u2019s useful and it\u2019s only useful once or twice a week",
            "score": 1,
            "replies": []
        },
        {
            "author": "kjbreil",
            "body": "Sounds like you are trying to extend some current functionality, try pointing the ai to the current implementations and telling it to analyze that before doing anything, then ask it to extend it, for example I would say \u201cuse @xyzFunction as an example of how to do things, make a new function based on that but for @zyxModel. Watch what it does right at the start, if it doesn\u2019t start down the right route stop it right away and correct it. Think of it as mentoring a junior and pair programming with it. Too much at once won\u2019t work well and not detailed enough won\u2019t work well. If you get the right workflow it can REALLY increase productivity and help create great code just like a junior would.",
            "score": 1,
            "replies": []
        },
        {
            "author": "lord_heskey",
            "body": "Idk but ive found chatgpt super useful. I do the thinking, it does the boring boilerplate code. Its my bestie.",
            "score": 1,
            "replies": []
        },
        {
            "author": "MythoclastBM",
            "body": "Was never going to. At current AI models could maybe be save me 10 minutes of work every other week. I'm so over the buzz about AI. Current AI isn't Cortana, it's Cortana. Remember when Microsoft was pushing Cortana super hard like 10 years ago? I member. How did that work out?",
            "score": 1,
            "replies": []
        },
        {
            "author": "beastkara",
            "body": "Give it a few years. Not everything is instant",
            "score": 1,
            "replies": []
        },
        {
            "author": "Comprehensive-Pin667",
            "body": "3.7 is relatively good for boiler-plate-y stuff, even in Github Copilot's agent mode. I can let it create the plumbing and work on the more interesting bits while it's creating the plumbing. It's quite slow BTW, so waiting for it to create the plumbing would probably not be quicker than just making it myself using my JetBrains IDE, which would also auto-suggests a lot of stuff along the way. It did this long before AI.",
            "score": 1,
            "replies": []
        },
        {
            "author": "NanoYohaneTSU",
            "body": "You're right. But companies don't see it that way. These next 2 years are going to see lots of no hiring. Until they realize they need devs and will hire again. Same thing happened when they outsourced to india.",
            "score": 1,
            "replies": []
        },
        {
            "author": "frankywaryjot",
            "body": "Replace no, but limit significantly the number of members of a team? In mu opinion yes, it happens now already. More senior devs are more productive and companies know that so they don't employ",
            "score": 1,
            "replies": []
        },
        {
            "author": "Individual-Dingo9385",
            "body": "The only viable use case for LLMs for me is to generate some boilerplate code or basic stuff since its release, and I use it a lot for non-CS stuff. For more complex logic, they are getting lost, or I find it quicker to express my thoughts in code directly. Other than that, it hallucinates way too much and is unreliable.",
            "score": 1,
            "replies": []
        },
        {
            "author": "FewCelebration9701",
            "body": "Yet? I'd argue never. Not until we achieve something near AGI (as in, there's a real and robust argument over whether its as been obtained because it is fully capable of replacing a human mind).\n\n  \nI'm confident in saying that the only people who ever bought into the \"it is replacing us\" narrative are:\n\n1. Fear mongers who make money via outrage/doomer influencing (I've noticed a lot of former \"learn to code\" influencers are now AI doomerists serving slop to the same audience they told to try and break into CS).\n\n\n\n2. Mostly tech illiterate people who cannot separate science fiction from reality.\n\n\n\n3. Corporate politicians. As in, CEOs and whatnot. People who don't do actual work, and whose job exists solely to make political gestures to a board of directors and shareholders more broadly.\n\n\n\n4. Doomers. The kind of people who throw the word \"enshittification\" around but never read the original article by Doctorow, let alone any of his other works. This includes political activists who have invaded the entire tech sector in the last few years. The kind of people whose political beliefs are their only personality traits, and have turned AI into a very political topic instead of a technical one. The people who are contrarians and anything one side is for, they must be against and vice versa. \n\n  \n5. Finally, people with financial stakes in AI solutions doing well, like Altman of course.\n\n  \nThese LLMs were always going to be basically the next Intellisense for us. Were this not the case, then companies wouldn't be just pouring money into outsourcing our jobs to India, Vietnam, and Mexico. Why stand up all that infrastructure and sign those long term contracts if we are just a few years away? \n\n  \nIt allows us to--**potentially**\\--be way more efficient. But you still need to know what the hell you're doing otherwise you end up like those (and I hate to use a new buzzword here...) vibe coders.\n\n  \nOur craft seriously needs a campaign to dissuade people who don't have a legitimate love for tech from joining. Maybe all this current market pain will help with that. But the thing that doomers refuse to understand is: if AI can do our jobs, then no knowledge worker is safe. Folks here really act like accounting or actuaries will be safe harbors.\n\n  \nThe grass is always greener because of all the manure.",
            "score": 1,
            "replies": []
        },
        {
            "author": "Main-Eagle-26",
            "body": "Used Cursor to fix a medium complexity bug and my manager was blown away to see it used to do anything other than greenfield work.\n\nI was experimenting with using it and purely writing code with prompts to fix the bug, and it took a couple of dozen prompts. The solution ended up adding another new bug, which I then used prompts to fix as well.\n\nThere's a ceiling for this technology here and it isn't a high one. There's no conceivable way to improve it much beyond where it's at right now. It gets senior leadership excited, though.",
            "score": 1,
            "replies": []
        },
        {
            "author": "justUseAnSvm",
            "body": "No, they won't, but AI is having a big influence on how we manage technical projects.\n\nThe big shift right now is towards the \"player coach\" model. Instead of an army of engineering managers overseeing teams, personal management will bump up one level to the Director, and the technical execution of the team will fall onto tech leads, who are responsible for a larger slice of planning, execution, and product management.\n\nWhat you're essentially doing to tying outcomes to a single engineer, and having them figure out how to execute. Along with that, there will be several additional people on the team.\n\nAI is a major augment to this model, because it frees up software engineers to do more than just crush tickets for 8 hours a day, and gives us more space to plan, management, and organize. As AI gets better, we'll just need fewer people on a team to get the same work done.\n\nHowever, AI can't ever fully get rid of programmers, since the job of owning a technical outcome will always exist, it will just shift the distribution of tasks you do in order to achieve that.",
            "score": 1,
            "replies": [
                {
                    "author": "ChiDeveloperML",
                    "body": "Well, then we\u2019ll want more products and the engineers will get shifted to working on more things",
                    "score": 2,
                    "replies": []
                }
            ]
        },
        {
            "author": "PopFun7873",
            "body": "Don't use an LLM for that, that's insane. I guess you could use an LLM to help you write a simple algorithm/transformation for this, but don't use something deterministic for a repetitive task that requires non-determinism.",
            "score": 1,
            "replies": []
        },
        {
            "author": "internetroamer",
            "body": "How is everyone missing the point. \n\nYou don't need to replace 100% of software engineers. Simply reducing the work or demand for 5% of software development would make a noticeable impact on the job market. Reduce 10% of the work and then you end up seeing slower hiring and lower wages and less perks like WFH.\n\nThen scale over course of next decade. It's not looking good and will obviously have downward pressure on wages",
            "score": 1,
            "replies": []
        },
        {
            "author": "painedHacker",
            "body": "I dont think they will replace engineers but they can make them more productive so arguably you would need fewer of them.  Hard to tell how it will go",
            "score": 0,
            "replies": []
        },
        {
            "author": "No-Explanation7647",
            "body": "We\u2019re too stupid to invent real intelligence. Only God can do that.",
            "score": -2,
            "replies": [
                {
                    "author": "0x7c365c",
                    "body": "The worst part about modern society is that I have to sit here and entertain your delusions because saying what I really think is somehow \"rude\".",
                    "score": 5,
                    "replies": [
                        {
                            "author": "No-Explanation7647",
                            "body": "Huh, what?",
                            "score": -2,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "mosenco",
            "body": "with gpt, there is a specific implementation to force the model to produce an output that follows a structure that you define so the model won't create something new. also there is a parameter where you set it to 0 so it won't try to say something weird or new, but stick to the prompt and act more like an algorithm\n\ni dunno for sonnet tho, never used",
            "score": -5,
            "replies": []
        }
    ]
}