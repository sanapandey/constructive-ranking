{
    "title": "Are there any free working voice cloning AIs?",
    "author": "Dear-Presentation871",
    "subreddit": "StableDiffusion",
    "rank": 17,
    "score": 19,
    "upvote_ratio": 0.74,
    "num_comments (reported by reddit)": 43,
    "url": "https://www.reddit.com/r/StableDiffusion/comments/1je3b9m/are_there_any_free_working_voice_cloning_ais/",
    "id": "1je3b9m",
    "selftext": "I remember this being all the rage a year ago but all the things that came out then was kind of ass, and considering how much AI has advanced in just a year, are there nay modern really good ones?",
    "comments": [
        {
            "author": "swagonflyyyy",
            "body": "XTTSv2 by far the best one you can run locally. Use this API to run it locally:\n\n[https://github.com/coqui-ai/TTS](https://github.com/coqui-ai/TTS)\n\nBut it has a restricted license, so no commercial use allowed.\n\nBasically, you need a voice sample of one CLEAN, COMPLETE, NOISE-FREE audio clip at least 6 seconds long. Make sure to include a complete sentence and absolutely no background noise. The model is extremely good but extremely sensitive to artifacts in audio.",
            "score": 17,
            "replies": [
                {
                    "author": "atlas_brazil",
                    "body": "Honest question, how do they know it was used commercially?",
                    "score": 4,
                    "replies": [
                        {
                            "author": "biscotte-nutella",
                            "body": "they probably insert inaudible things in the sound that can be detected instantly.\n\nAdobe can tell if you used adobe premiere on your project just from a few frames of video.",
                            "score": 6,
                            "replies": [
                                {
                                    "author": "thecoolrobot",
                                    "body": "Any source/reference for your comment about Adobe? I can\u2019t find any mention of that online.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "biscotte-nutella",
                                            "body": "friend that works in events told me someone he knows video projected something for a concert that was edited with premiere, and their production company got an email from adobe saying to buy a license or be sued... It's a second hand account it's not good a source sorry.",
                                            "score": 3,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "swagonflyyyy",
                            "body": "Don't.",
                            "score": 6,
                            "replies": []
                        },
                        {
                            "author": "Zonca",
                            "body": "Im no tech wizard, but you can probably get around this at the cost of losing some quality, there are probably some better methods than recording it again from your pc to your phone, but thats the idea.",
                            "score": 1,
                            "replies": []
                        },
                        {
                            "author": "skarrrrrrr",
                            "body": "You can encode messages in an audio signal",
                            "score": 1,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "skarrrrrrr",
                    "body": "where do you see the commercial use thing ? This software has a Mozilla 2.0 license. Do you mean a license at the model level ?",
                    "score": 2,
                    "replies": []
                },
                {
                    "author": "TurbTastic",
                    "body": "2 questions. Does this benefit from using a few minutes of audio instead of only a few seconds? Are there any free/easy options to cleanup mild background static noise before using the audio clip?",
                    "score": 2,
                    "replies": [
                        {
                            "author": "remghoost7",
                            "body": "I've personally found that XTTSv2's voice cloning works best with 10-30 seconds of input audio.  \nIf you get over a minute, it starts to get wonky (at least, from my testing).\n\nIf I recall correctly, [gitmylo's audio-webui](https://github.com/gitmylo/audio-webui?tab=readme-ov-file#-automatic-installers) can finetune XTTSv2 models with longer input audio (I think it prefers an hour or two). I haven't tried that frontend in over a year though, so I don't know what's changed. I also found that a good 10-30 second clip gets about 90% of the way there anyways.\n\n\\---\n\nIf you want to mess around with an all-in-one frontend, I'd recommend [alltalk\\_tts](https://github.com/erew123/alltalk_tts).  \nIt's definitely my go-to.\n\nIt also has support for a few other models as well (piper, parler, f5tts, vits, and xttsv2), some of which can do cloning as well. I've found that XTTSv2 works best for my use cases, but some people prefer piper. \n\nIt can also run as an API server and can plug into some LLM frontends (I primarily use llamacpp+SillyTavern).\n\nI believe alltalk\\_tts has a pitch extraction mode which can \"clean up\" some input audio. Haven't used that feature myself though, so I can't really speak on it.\n\n\\---\n\nAlso, just a bit of soapboxing, I really wish the [kokoro](https://huggingface.co/hexgrad/Kokoro-82M) dev would get off of their high horse and release training code.\n\nKokoro is *objectively* the best locally hosted TTS engine out there. It beats base XTTSv2 in every conceivable metric (intonation, composition, etc). And it's fast as heck (even on CPU alone). Especially using this [Kokoro-FastAPI](https://github.com/remsky/Kokoro-FastAPI) fork.\n\nIt's allegedly just a modified version of XTTSv2, which means it *could* support cloning. It would be an insane leap forwards for voice cloning if it were fully released. But they're super hush-hush about the entire project for some reason. Some people are guessing that they used ElevenLabs audio for the input, which would be a breach of TOS apparently. Or they're just trying to lock it down and sell it.\n\nidk. Either way, super annoying. haha.\n\n\\-end rant-",
                            "score": 5,
                            "replies": [
                                {
                                    "author": "TurbTastic",
                                    "body": "Thanks for all the info. I'll give some of these a try next time I do some testing. I've tried a few 5-10 second solutions and they were very underwhelming. 50-70% accurate is pointless for me, but getting around 90% should be good enough.",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "remghoost7",
                                            "body": "It depends *a lot* on the input audio. Some of the lower quality inputs I've tried struggled a tad.   \nBut honestly, if you get a good sentence or two, you're probably fine.\n\nI've also used Audacity to de-noise/de-hiss some input audio in the past.\n\nAnd technically, like you can do with ControlNet, if you get it to generate a usable chunk of audio, you can feed that back into XTTSv2. Granted, it'll be *slightly* different, but you could use that as a method of \"cleaning up\" the audio.",
                                            "score": 3,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "author": "swagonflyyyy",
                            "body": "Not sure about your first question. I think it just needs one good sample.\n\nAs for the second one, there should be plenty of software out there for that. I think ElevenLabs has one such filter.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                },
                {
                    "author": "LucidFir",
                    "body": "You're on outdated info. Even this is outdated. \n\nTldr: f5tts e2tts\n\nThere are so many models! https://artificialanalysis.ai/text-to-speech/arena\n\nDec2024\n\nhttps://huggingface.co/geneing/Kokoro\n\nNewest, October 2024:\n\nF5-TTS and E2-TTS [https://www.youtube.com/watch?v=FTqAQvARMEg](https://www.youtube.com/watch?v=FTqAQvARMEg)   \nGithub Page: [https://github.com/SWivid/F5-TTS](https://github.com/SWivid/F5-TTS)   \nCode: [https://swivid.github.io/F5-TTS/](https://swivid.github.io/F5-TTS/)   \nAI Model : [https://huggingface.co/SWivid/F5-TTS](https://huggingface.co/SWivid/F5-TTS)\n\n...\n\nYou want to hang out in r/AIVoiceMemes\n\nCoqui is fast but the voices are bad.\n\nTortoise is slow and unreliable but the voices are often great.\n\nStyleTTS2 is meant to be great and fast, but I could never figure out how to run it.\n\nThe key difference between Style and Coqui is that, I believe (things change), that you can train StyleTTS2.\n\nRVC does voice to voice, if you're struggling to get the \\*\\*\\*precise\\*\\*\\* pacing then you should speak into a mic and voice clone it with RVC.\n\nYou will want to seek podcasts and audiobooks on YouTube to download for audio sources.\n\nYou will want to use UVR5 to separate vocals from instrumentals if that becomes a thing.\n\nYou will eventually want to try lip syncing video, for that you will use EasyWav2Lip or possibly Face Fusion.\n\nIf you're having difficulty with install, there are Pinokio installs of a lot of TTS that can be easier to use, but are more limited.\n\nCheck out Jarod's Journey for all of the advice, especially about Tortoise: [https://www.youtube.com/@Jarods\\_Journey](https://www.youtube.com/@Jarods_Journey)\n\nCheck out P3tro for the only good installation tutorial about RVC: [https://www.youtube.com/watch?v=qZ12-Vm2ryc&t=58s&ab\\_channel=p3tro](https://www.youtube.com/watch?v=qZ12-Vm2ryc&t=58s&ab_channel=p3tro)\n\nEdit: Jarod made a gui for StyleTTS2. Also, try alltalk?\n\nEdit: u/a_beautifil_rhind \n\nstyletts has a better model called vokan.\nhttps://huggingface.co/ShoukanLabs/Vokan/tree/main/Model\n\nThere's also fish-audio now in addition to xtts. Also voicecraft.\n\nEdit: u/tavirabon\n\nCoqui (XTTS) can be finetuned https://github.com/daswer123/xtts-finetune-webui\n\nAlso https://github.com/RVC-Boss/GPT-SoVITS which is a step up from other zero-shot TTS and most few-shot TTS (>1 minute of clear natural speech) finetuning\n\nEdit: u/battlerepulsiveO\n\nYou can use the huggingface model of XTTS V2 because there are people who have finetuned XTTS V2 before. It's really simple to train with different methods like one that has automated for you where you just drop in the audio files. Or you can personally create a dataset and a csv file with the name of the audio file and the transcription, and all the wav files should be stored inside a wav folder. It all depends on the notebook you're using.\n\nEdit: u/dumpimel\n\nhave you tried alltalk? it's based on coqui\n\nhttps://github.com/erew123/alltalk_tts\n\nyou drop a 20s .wav in the \"voices\" folder and it's pretty decent at reproducing the voice\n\nthey also say you can finetune it further",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "No-Issue-9136",
                    "body": "F5 is better",
                    "score": 1,
                    "replies": [
                        {
                            "author": "joran213",
                            "body": "Hard disagree. F5 struggles a lot with longer sentences and is just less reliable from my experience. When it does work, it is pretty good tho.",
                            "score": 1,
                            "replies": [
                                {
                                    "author": "No-Issue-9136",
                                    "body": "For me it's realism in cloning over all. I don't mind short sentences",
                                    "score": 1,
                                    "replies": [
                                        {
                                            "author": "joran213",
                                            "body": "Yeah I care more about intonation and a natural sounding flow, and xtts is pretty much the best at this. The actual speech quality isn't fantastic, but that can be improved using a RVC pass on top of it.",
                                            "score": 1,
                                            "replies": []
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "author": "Altruistic_Heat_9531",
            "body": "[https://github.com/SparkAudio/Spark-TTS](https://github.com/SparkAudio/Spark-TTS), this is the latest, and only need couple of sec of audio\n\nedit : Oh and, apache license",
            "score": 10,
            "replies": [
                {
                    "author": "No-Issue-9136",
                    "body": "Better than f5?",
                    "score": 1,
                    "replies": [
                        {
                            "author": "Altruistic_Heat_9531",
                            "body": "About that, idk how to compare it. but i have a thick asian accent, and using Spark TTS, it successfully converts my voice into different accents, British, American, Australian, etc. so I\u2019m happy. Plus, it runs on my CPU, so no complaints about that.",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "TheDreamSymphonic",
            "body": "Just use RVC. It's speech to speech, but the intonation on all these other solutions isn't good anyway. Nobody has beaten RVC imo.",
            "score": 4,
            "replies": [
                {
                    "author": "joran213",
                    "body": "Isn't RVC like 2 years old at this point? Are there updates or better alternatives? Or is original RVC still SOTA?",
                    "score": 1,
                    "replies": [
                        {
                            "author": "AconexOfficial",
                            "body": "the individual parts of rvc to the most part are not sota anymore, but no one tried to create a new whole model with newer sota modules from what I know.\n\nI actually was experimenting with that, trying to create something better with a newer architecture, but it's a lot of work and progress is slow so far",
                            "score": 1,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "the_doorstopper",
            "body": "Just to piggyback, how are you mean to use these things? Llms, and things like stable diffusion, have front ends, UIs for a Web, or app, which make them easy, but what about these?",
            "score": 2,
            "replies": [
                {
                    "author": "Moist-Apartment-6904",
                    "body": "You run the code with Python from the command line.",
                    "score": 1,
                    "replies": []
                },
                {
                    "author": "joran213",
                    "body": "If you know a tiny bit of python it should be doable to use the example code in some basic python scripts to do what you need. If not, ask chatgpt for help.",
                    "score": 1,
                    "replies": []
                }
            ]
        },
        {
            "author": "Kreature",
            "body": "this was released in Jan: [https://huggingface.co/spaces/zouyunzouyunzouyun/llasa-8b-tts](https://huggingface.co/spaces/zouyunzouyunzouyun/llasa-8b-tts) it needs at least 5 seconds of a voice.\n\nthere are better ones out but this is an easy one.",
            "score": 2,
            "replies": []
        },
        {
            "author": "Embarrassed-Hope-571",
            "body": "https://github.com/coqui-ai/TTS this works wellif the sample is clean",
            "score": 5,
            "replies": []
        },
        {
            "author": "the_friendly_dildo",
            "body": "https://huggingface.co/Zyphra/Zonos-v0.1-hybrid",
            "score": 4,
            "replies": []
        },
        {
            "author": "pasjojo",
            "body": "Tryeplay.io if you have a good machine. Otherwise weights.gg has a free training plan.",
            "score": 2,
            "replies": []
        },
        {
            "author": "MaruluVR",
            "body": "GPT Sovits V3 just released it supports English, Chinese, Japanese, Korean and Cantonese. From my personal testing it currently is the best option for 0 shot voice cloning in Japanese. Its MIT licensed and needs audio between 5 and 10 seconds for cloning.  [https://github.com/RVC-Boss/GPT-SoVITS/releases/tag/20250228v3](https://github.com/RVC-Boss/GPT-SoVITS/releases/tag/20250228v3)",
            "score": 1,
            "replies": []
        },
        {
            "author": "martinerous",
            "body": "I've had good success with Applio: [https://github.com/IAHispano/Applio](https://github.com/IAHispano/Applio) which is a wrapper around TTS and voice cloning \n\nCan also be installed in Pinokio, if you are using it.",
            "score": 1,
            "replies": []
        },
        {
            "author": "acedelgado",
            "body": "Alltalk v2 is a solid gui that uses a few different models, the best of which are F5 (good zero shot but will always reproduce inflections from the sample audio. So if they sound angry, they'll always sound angry. If they have a stutter, they'll always stutter.) and coqui xttsv2  (which is really good if you run the fine-tune script but you'll need a few minutes of clear audio, and it'll give random inflections every time.)\n\n[https://github.com/erew123/alltalk\\_tts/tree/alltalkbeta](https://github.com/erew123/alltalk_tts/tree/alltalkbeta)\n\nZonos is the latest zero-shot one I've used, and while it's slightly less quality, mixing up the emotional guidance actually works to get more of the inflection you'd want.\n\n[https://github.com/Zyphra/Zonos](https://github.com/Zyphra/Zonos)",
            "score": 1,
            "replies": []
        },
        {
            "author": "Dezordan",
            "body": "Last thing I heard about voice cloning was [F5-TTS](https://swivid.github.io/F5-TTS/), it can clone based on references. But it also quite old at this point.",
            "score": 1,
            "replies": [
                {
                    "author": "Iamcubsman",
                    "body": "[https://github.com/niknah/ComfyUI-F5-TTS](https://github.com/niknah/ComfyUI-F5-TTS) \n\nThe last update for the ComfyUI node was a little over a week ago so the code seems to be maintained but I don't know enough about the underlying tech to say if it is out of date. Has anybody used it lately? What are your thoughts on it?",
                    "score": 2,
                    "replies": [
                        {
                            "author": "nimby900",
                            "body": "This is extremely good for most simple voice cloning purposes. I have used it locally.",
                            "score": 0,
                            "replies": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "wanderingandroid",
            "body": "Weights.gg has a bunch of cloned voices that you can use for free.",
            "score": 1,
            "replies": []
        },
        {
            "author": "Hullefar",
            "body": "Is there one that works on any language?\u00a0",
            "score": 1,
            "replies": []
        },
        {
            "author": "gmorks",
            "body": "on the same topic is there a way to create, not clone, a voice?",
            "score": 1,
            "replies": []
        },
        {
            "author": "77-81-6",
            "body": "Here are samples of well known cloned voices.\nMade with XTTS.\n\nhttps://www.soundcloud.com/cylonius",
            "score": 1,
            "replies": []
        },
        {
            "author": "Big3gg",
            "body": "Use ElevenLabs.",
            "score": -1,
            "replies": []
        }
    ]
}